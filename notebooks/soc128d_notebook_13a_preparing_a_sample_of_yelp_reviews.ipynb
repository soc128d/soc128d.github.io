{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e834ea70",
   "metadata": {},
   "source": [
    "#### Sociology 128D: Mining Culture Through Text Data: Introduction to Social Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2bb65a",
   "metadata": {},
   "source": [
    "# Notebook 13a: Preparing a Sample of Yelp Reviews\n",
    "\n",
    "For most students, it will make sense to complete Notebook 13b (the companion notebook) on Google Colab, where you can more easily rely a GPU. Notebook 13a helps streamline the process of extracting relevant reviews and useful features from the large files that come as part of the Yelp Open Dataset. In this notebook, we will identify restaurant reviews from January 2019 to January 2021 with data about the price range, and we will save a sample of these reviews as a dataframe in the JSON format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb01a46",
   "metadata": {},
   "source": [
    "### Getting the Data\n",
    "\n",
    "For this notebook, we are going to use the Yelp Open Dataset, which you can find [here](https://www.yelp.com/dataset). You'll have to click 'Download Dataset', agree to the terms, and click 'Download JSON'. It's a large download: ~5GB compressed and ~11GB once you've uncompressed it. The dataset has 8,635,403 reviews of businesses including text, a rating out of five stars, and various other information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbcd13e",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "You may need to install `contractions`,  `num2words`, and `unidecode`. You can install two of these using `conda` (if using Anaconda), but you will need to install `contractions` using `pip` (see below).\n",
    "\n",
    "`conda install -c conda-forge num2words` <br>\n",
    "`conda install -c conda-forge unidecode` <br>\n",
    "\n",
    "`pip install contractions`\n",
    "\n",
    "**Note: If you have trouble getting `contractions` to work, you can also comment out or delete both the line that imports it and the line that reads \"<tt>doc = contractions.fix(doc)</tt>\" in the cell that defines the <tt>preprocess_doc</tt> function.** You can disable or change other aspects of the preprocessing as you see fit. Just keep in mind what the preprocessing is meant to accomplish and how the different steps interact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "593801ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions\n",
    "import datetime as dt\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "from collections import Counter\n",
    "from gensim.models.phrases import Phrases\n",
    "from num2words import num2words\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfec1bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(6756) # from random.org"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d095aa4c",
   "metadata": {},
   "source": [
    "### The Files\n",
    "\n",
    "The main file, <tt>yelp_academic_dataset_review.json</tt>, is quite large (> 6GB). We are not going to examine all of it, so we are going to avoid reading it into memory all at once. We are going to extract some information from the <tt>yelp_academic_dataset_business.json</tt> file, which has information about the businesses in the dataset. We will then use the business IDs and the date of reviews to select only the reviews we want to examine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ee0bc02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dataset_User_Agreement.pdf',\n",
       " 'yelp_academic_dataset_business.json',\n",
       " 'yelp_academic_dataset_checkin.json',\n",
       " 'yelp_academic_dataset_review.json',\n",
       " 'yelp_academic_dataset_tip.json',\n",
       " 'yelp_academic_dataset_user.json']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"yelp_dataset/\") # this should point to the where you have downloaded and extracted the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2958360",
   "metadata": {},
   "source": [
    "### Identifying Reviews to Keep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d41a9b8",
   "metadata": {},
   "source": [
    "First, read in the file with information about businesses and take a look at the resulting dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4d39b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "biz_df = pd.read_json(\"yelp_dataset/yelp_academic_dataset_business.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1fdd120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "      <th>attributes</th>\n",
       "      <th>categories</th>\n",
       "      <th>hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6iYb2HFDywm3zjuRg0shjw</td>\n",
       "      <td>Oskar Blues Taproom</td>\n",
       "      <td>921 Pearl St</td>\n",
       "      <td>Boulder</td>\n",
       "      <td>CO</td>\n",
       "      <td>80302</td>\n",
       "      <td>40.017544</td>\n",
       "      <td>-105.283348</td>\n",
       "      <td>4.0</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RestaurantsTableService': 'True', 'WiFi': 'u...</td>\n",
       "      <td>Gastropubs, Food, Beer Gardens, Restaurants, B...</td>\n",
       "      <td>{'Monday': '11:0-23:0', 'Tuesday': '11:0-23:0'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tCbdrRPZA0oiIYSmHG3J0w</td>\n",
       "      <td>Flying Elephants at PDX</td>\n",
       "      <td>7000 NE Airport Way</td>\n",
       "      <td>Portland</td>\n",
       "      <td>OR</td>\n",
       "      <td>97218</td>\n",
       "      <td>45.588906</td>\n",
       "      <td>-122.593331</td>\n",
       "      <td>4.0</td>\n",
       "      <td>126</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RestaurantsTakeOut': 'True', 'RestaurantsAtt...</td>\n",
       "      <td>Salad, Soup, Sandwiches, Delis, Restaurants, C...</td>\n",
       "      <td>{'Monday': '5:0-18:0', 'Tuesday': '5:0-17:0', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bvN78flM8NLprQ1a1y5dRg</td>\n",
       "      <td>The Reclaimory</td>\n",
       "      <td>4720 Hawthorne Ave</td>\n",
       "      <td>Portland</td>\n",
       "      <td>OR</td>\n",
       "      <td>97214</td>\n",
       "      <td>45.511907</td>\n",
       "      <td>-122.613693</td>\n",
       "      <td>4.5</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>{'BusinessAcceptsCreditCards': 'True', 'Restau...</td>\n",
       "      <td>Antiques, Fashion, Used, Vintage &amp; Consignment...</td>\n",
       "      <td>{'Thursday': '11:0-18:0', 'Friday': '11:0-18:0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oaepsyvc0J17qwi8cfrOWg</td>\n",
       "      <td>Great Clips</td>\n",
       "      <td>2566 Enterprise Rd</td>\n",
       "      <td>Orange City</td>\n",
       "      <td>FL</td>\n",
       "      <td>32763</td>\n",
       "      <td>28.914482</td>\n",
       "      <td>-81.295979</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RestaurantsPriceRange2': '1', 'BusinessAccep...</td>\n",
       "      <td>Beauty &amp; Spas, Hair Salons</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PE9uqAjdw0E4-8mjGl3wVA</td>\n",
       "      <td>Crossfit Terminus</td>\n",
       "      <td>1046 Memorial Dr SE</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>30316</td>\n",
       "      <td>33.747027</td>\n",
       "      <td>-84.353424</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>{'GoodForKids': 'False', 'BusinessParking': '{...</td>\n",
       "      <td>Gyms, Active Life, Interval Training Gyms, Fit...</td>\n",
       "      <td>{'Monday': '16:0-19:0', 'Tuesday': '16:0-19:0'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                     name              address  \\\n",
       "0  6iYb2HFDywm3zjuRg0shjw      Oskar Blues Taproom         921 Pearl St   \n",
       "1  tCbdrRPZA0oiIYSmHG3J0w  Flying Elephants at PDX  7000 NE Airport Way   \n",
       "2  bvN78flM8NLprQ1a1y5dRg           The Reclaimory   4720 Hawthorne Ave   \n",
       "3  oaepsyvc0J17qwi8cfrOWg              Great Clips   2566 Enterprise Rd   \n",
       "4  PE9uqAjdw0E4-8mjGl3wVA        Crossfit Terminus  1046 Memorial Dr SE   \n",
       "\n",
       "          city state postal_code   latitude   longitude  stars  review_count  \\\n",
       "0      Boulder    CO       80302  40.017544 -105.283348    4.0            86   \n",
       "1     Portland    OR       97218  45.588906 -122.593331    4.0           126   \n",
       "2     Portland    OR       97214  45.511907 -122.613693    4.5            13   \n",
       "3  Orange City    FL       32763  28.914482  -81.295979    3.0             8   \n",
       "4      Atlanta    GA       30316  33.747027  -84.353424    4.0            14   \n",
       "\n",
       "   is_open                                         attributes  \\\n",
       "0        1  {'RestaurantsTableService': 'True', 'WiFi': 'u...   \n",
       "1        1  {'RestaurantsTakeOut': 'True', 'RestaurantsAtt...   \n",
       "2        1  {'BusinessAcceptsCreditCards': 'True', 'Restau...   \n",
       "3        1  {'RestaurantsPriceRange2': '1', 'BusinessAccep...   \n",
       "4        1  {'GoodForKids': 'False', 'BusinessParking': '{...   \n",
       "\n",
       "                                          categories  \\\n",
       "0  Gastropubs, Food, Beer Gardens, Restaurants, B...   \n",
       "1  Salad, Soup, Sandwiches, Delis, Restaurants, C...   \n",
       "2  Antiques, Fashion, Used, Vintage & Consignment...   \n",
       "3                         Beauty & Spas, Hair Salons   \n",
       "4  Gyms, Active Life, Interval Training Gyms, Fit...   \n",
       "\n",
       "                                               hours  \n",
       "0  {'Monday': '11:0-23:0', 'Tuesday': '11:0-23:0'...  \n",
       "1  {'Monday': '5:0-18:0', 'Tuesday': '5:0-17:0', ...  \n",
       "2  {'Thursday': '11:0-18:0', 'Friday': '11:0-18:0...  \n",
       "3                                               None  \n",
       "4  {'Monday': '16:0-19:0', 'Tuesday': '16:0-19:0'...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biz_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05c65f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160585, 14)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biz_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a6a164",
   "metadata": {},
   "source": [
    "Let's take a look at the <tt>attributes</tt> column. Each row (business) has its own dictionary of attributes. Let's iterate through the rows and add each key to one set so we can examine the unique list of keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2b60e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "attr_keys = set()\n",
    "for idx, row in biz_df.iterrows():\n",
    "    atts = row.attributes\n",
    "    if atts:\n",
    "        for key in atts.keys():\n",
    "            attr_keys.add(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30804c1",
   "metadata": {},
   "source": [
    "As in Notebook 12, we'll use the values for \"RestaurantsPriceRange2\" (but you can use others if you'd like)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "182100b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'AcceptsInsurance',\n",
       " 'AgesAllowed',\n",
       " 'Alcohol',\n",
       " 'Ambience',\n",
       " 'BYOB',\n",
       " 'BYOBCorkage',\n",
       " 'BestNights',\n",
       " 'BikeParking',\n",
       " 'BusinessAcceptsBitcoin',\n",
       " 'BusinessAcceptsCreditCards',\n",
       " 'BusinessParking',\n",
       " 'ByAppointmentOnly',\n",
       " 'Caters',\n",
       " 'CoatCheck',\n",
       " 'Corkage',\n",
       " 'DietaryRestrictions',\n",
       " 'DogsAllowed',\n",
       " 'DriveThru',\n",
       " 'GoodForDancing',\n",
       " 'GoodForKids',\n",
       " 'GoodForMeal',\n",
       " 'HairSpecializesIn',\n",
       " 'HappyHour',\n",
       " 'HasTV',\n",
       " 'Music',\n",
       " 'NoiseLevel',\n",
       " 'Open24Hours',\n",
       " 'OutdoorSeating',\n",
       " 'RestaurantsAttire',\n",
       " 'RestaurantsCounterService',\n",
       " 'RestaurantsDelivery',\n",
       " 'RestaurantsGoodForGroups',\n",
       " 'RestaurantsPriceRange2',\n",
       " 'RestaurantsReservations',\n",
       " 'RestaurantsTableService',\n",
       " 'RestaurantsTakeOut',\n",
       " 'Smoking',\n",
       " 'WheelchairAccessible',\n",
       " 'WiFi'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(attr_keys))\n",
    "attr_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baccbefd",
   "metadata": {},
   "source": [
    "Now let's take a look at the <tt>categories</tt> field. We'll use `biz_df.categories.tolist()` to convert the column to a list (one element per row), and then iterate through that inside a list comprehension. Each row with data for this column has a single string of categories separated by columns. We'll use `str.split(\",\")` to split these into lists on the columns, then use a second list comprehension to go from a list of lists to a single (\"flat\") list of categories. In the second list comprehension, where we're iterating through individual categories, we'll also use the `str.strip()` method to get rid of whitespace on either side of each token.\n",
    "\n",
    "Finally, we'll take a look at the number of unique categories and then use `Counter` to see which are most common. It's set to show the 20 most common, but you can change that argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "470b53a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = [cat.split(\",\") for cat in biz_df.categories.tolist() if cat]\n",
    "cats = [cat.strip() for cat_list in cats for cat in cat_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8329183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1330"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(cats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0564e1d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Restaurants', 50763),\n",
       " ('Food', 29469),\n",
       " ('Shopping', 26205),\n",
       " ('Beauty & Spas', 16574),\n",
       " ('Home Services', 16465),\n",
       " ('Health & Medical', 15102),\n",
       " ('Local Services', 12192),\n",
       " ('Nightlife', 11990),\n",
       " ('Bars', 10741),\n",
       " ('Automotive', 10119),\n",
       " ('Event Planning & Services', 9644),\n",
       " ('Active Life', 9231),\n",
       " ('Coffee & Tea', 7725),\n",
       " ('Sandwiches', 7272),\n",
       " ('Fashion', 6599),\n",
       " ('American (Traditional)', 6541),\n",
       " ('Hair Salons', 5900),\n",
       " ('Pizza', 5756),\n",
       " ('Hotels & Travel', 5703),\n",
       " ('Breakfast & Brunch', 5505)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(cats).most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8f2858",
   "metadata": {},
   "source": [
    "Now we want to find the IDs of businesses that (1) are restaurants and (2) have data about how expensive they are. We can subset the data to include only rows that contain \"Restaurants\" in the <tt>categories</tt> field (this is the most common term, in fact). To do that, we'll first include a condition that excludes rows with *no* data for that field. This allows us to use `str.contains` in the second condition (which wouldn't work with rows with missing data in the form of NaNs, for example).\n",
    "\n",
    "To keep things simple, we'll then iterate through the subset of rows with \"Restaurants\" in the <tt>categories</tt> field and check if the <tt>attributes</tt> field for each row has evaluated to a `dict`. If it has, we'll check whether there is data for the \"RestaurantsPriceRange2\" key. If there is, we'll add the row's <tt>busisness_id</tt> to our list of IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "409727fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44849\n",
      "Wall time: 2.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "restaurant_ids = set() # set for faster lookup later\n",
    "\n",
    "for idx, row in biz_df.loc[(biz_df.categories.notna()) & \n",
    "                           (biz_df.categories.str.contains(\"Restaurants\"))].iterrows():\n",
    "    attr = row.attributes\n",
    "    if type(attr) == dict:\n",
    "        if \"RestaurantsPriceRange2\" in attr.keys():\n",
    "            if attr[\"RestaurantsPriceRange2\"] not in [None, \"None\"]:\n",
    "                restaurant_ids.add(row.business_id)\n",
    "            \n",
    "print(len(restaurant_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad7884d",
   "metadata": {},
   "source": [
    "Iterating through that subset of <tt>biz_df</tt> is pretty fast. Next we need to iterate through the main file, which could take longer. We know we want reviews since the start of 2019, so we'll speed things up by checking whether each line (while it's a string) contains \"2019,\" \"2020,\" or \"2021\" before we convert the line to a dictionary. If a line has one of those years (as a string) in it, we'll use `json.loads` so we can interact with the line like it's a dictionary. First, we'll check whether the business ID associated with the review is in the set of IDs for businesses we are interested in (i.e., restaurants with price data). If a business ID is a match, we'll confirm the date of the review is from the start of 2019 or later.\n",
    "\n",
    "If a review is a match, we'll add a tuple consisting of the review ID and business ID to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0eab75f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "968091\n",
      "Wall time: 1min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "review_ids = []\n",
    "earliest_date = dt.datetime(2019, 1, 1)\n",
    "\n",
    "with open(\"yelp_dataset/yelp_academic_dataset_review.json\", \"r\", encoding=\"utf-8\") as reader:\n",
    "    for line in reader:\n",
    "        if any([year in line for year in [\"2019\", \"2020\", \"2021\"]]):\n",
    "            line = json.loads(line.strip())\n",
    "            if line[\"business_id\"] in restaurant_ids:\n",
    "                if pd.to_datetime(line[\"date\"]) >= earliest_date:\n",
    "                    review_ids.append((line[\"review_id\"], line[\"business_id\"]))\n",
    "print(len(review_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a51e00",
   "metadata": {},
   "source": [
    "Example tuple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d523955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('a7KaN1Li94o1au_8BfNi3Q', 'YZs1gNSh_sN8JmN_nrpxeA')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_ids[0] # review ID, business ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf32941d",
   "metadata": {},
   "source": [
    "Now we'll use `shuffle` to randomize the order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d8c3bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(review_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daada012",
   "metadata": {},
   "source": [
    "Now the first tuple is a different one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1450ade6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('JYpNH-1WQ2FccwE-30bFaA', 'kWSuSb-aIkHy0Jf3iz3CrA')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_ids[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a258934",
   "metadata": {},
   "source": [
    "Finally, we'll iterate through the tuples. If the second element (index 1) in the tuple, which is the business ID, is not already in the set <tt>biz_ids_tmp</tt>, we'll add the business ID to <tt>biz_ids_tmp</tt> and add the review ID to the set <tt>first_from_biz</tt>. If the business ID is already in <tt>biz_ids_tmp</tt>, we'll skip that review ID. This means that <tt>first_from_biz</tt> will only include the IDs of reviews if a review from the corresponding business had not already been added. We will only examine one review from any given business."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a23d6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 492 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "biz_ids_tmp = set()\n",
    "first_from_biz = set()\n",
    "\n",
    "for review in review_ids:\n",
    "    if review[1] not in biz_ids_tmp:\n",
    "        biz_ids_tmp.add(review[1])\n",
    "        first_from_biz.add(review[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16464cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30071"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(first_from_biz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f783987",
   "metadata": {},
   "source": [
    "Now we have a set of review IDs for reviews of restaurants with price data. The IDs are for reviews from January 1, 2019, onward, and we have just one per business after randomly sorting the initial list of IDs. All that's left is to iterate through the main file and find these reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a0eb050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30071\n",
      "Wall time: 31.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "reviews = []\n",
    "\n",
    "with open(\"yelp_dataset/yelp_academic_dataset_review.json\", \"r\", encoding=\"utf-8\") as reader:\n",
    "    for line in reader:\n",
    "        if any([year in line for year in [\"2019\", \"2020\", \"2021\"]]):\n",
    "            line = json.loads(line.strip())\n",
    "            if line[\"review_id\"] in first_from_biz:\n",
    "                reviews.append(line)\n",
    "print(len(reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1cd16a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'review_id': '4G1cR1njMkCWUPWMb0ZSJg', 'user_id': 'NTdi9yRSTD_RQn31fVvcCA', 'business_id': 'mP1EdIafQKMuOm9O4PzAfA', 'stars': 4.0, 'useful': 0, 'funny': 0, 'cool': 0, 'text': \"Pretty good service. Restaurant is on the more expensive side. For two people we ordered 7 tapas, two 3oz red wines and dessert. We got the bacon wrapped dates, potatas bravas, duck confit, pickled beets, steak tartare, mahi mahi, and the pulpo. My favorites were the steak tartare and the pickled beets. My boyfriend loved the duck confit. I personally thought it was a little too oily (but he doesn't like oily foods either so I was surprised when he said that). The pulpo was cooked very tenderly which my boyfriend liked, but I like my octopus a little chewier. The chocolate for the churros could've been a little thicker. My boyfriend thought the churros could've been smaller in thicker because he thought it should be crispier. Overall, good food :). PS our total was ~80 without tip.\\n\\nBoyfriend's opinion: The date bacon was a good mix of sweet and salty, texture was different, but the date was a little strong. Tartare was good, fresh, yolk was a good touch. The duck was rich but a little oily. Potato bravas was good aioli was nice, good crispiness. Octopus had good texture, but sauce could've been better. And the churros were ok, choco sauce couldve been better. Beet salad was good, strong flavors, the cheese clashed with it a bit. The mahi mahi was just ok, nothing to call home about (my least favorite was also the mahi mahi).\", 'date': '2019-01-30 22:26:00'}\n"
     ]
    }
   ],
   "source": [
    "print(reviews[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4790fb",
   "metadata": {},
   "source": [
    "Now, we can convert <tt>reviews</tt> (which is a list of dictionaries) to a dataframe. Pandas will use the keys of the dictionaries for the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "965a0740",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c491c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4G1cR1njMkCWUPWMb0ZSJg</td>\n",
       "      <td>NTdi9yRSTD_RQn31fVvcCA</td>\n",
       "      <td>mP1EdIafQKMuOm9O4PzAfA</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Pretty good service. Restaurant is on the more...</td>\n",
       "      <td>2019-01-30 22:26:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hKW_VNKuqQAYmy7LvNpJBA</td>\n",
       "      <td>aN0dAIbhE5x1Rac1ZGcmyg</td>\n",
       "      <td>y-MM8_RYgtvgyJojV1RWLg</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>So I have to give kudos to the lady taking my ...</td>\n",
       "      <td>2019-01-12 04:13:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_R1uDOBRo81FqMiyYWHJQ</td>\n",
       "      <td>vzfyQFBVzCsMTxgj4WjjqQ</td>\n",
       "      <td>DrEMFfzJIwsGZHl1AqKLrw</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>The ingredients are fresh here and the subs ar...</td>\n",
       "      <td>2019-02-02 20:46:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t-OmG9EDEYhIXHQHfuFBMw</td>\n",
       "      <td>YVYhnzICPx3tztqw83Mplg</td>\n",
       "      <td>ft-u7hmJk2b-UPdZrL55fw</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>The coffee is pretty good, when it's available...</td>\n",
       "      <td>2019-02-14 13:24:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K0X2DplCcYz-GB_Q96G3IQ</td>\n",
       "      <td>CqWXSfo_f5ZWUG-fxAmw3g</td>\n",
       "      <td>r_bcfIdazjqn-y7HP6rAUg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Food is BLAND, service is not good. Me and my ...</td>\n",
       "      <td>2019-01-11 18:05:24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  4G1cR1njMkCWUPWMb0ZSJg  NTdi9yRSTD_RQn31fVvcCA  mP1EdIafQKMuOm9O4PzAfA   \n",
       "1  hKW_VNKuqQAYmy7LvNpJBA  aN0dAIbhE5x1Rac1ZGcmyg  y-MM8_RYgtvgyJojV1RWLg   \n",
       "2  0_R1uDOBRo81FqMiyYWHJQ  vzfyQFBVzCsMTxgj4WjjqQ  DrEMFfzJIwsGZHl1AqKLrw   \n",
       "3  t-OmG9EDEYhIXHQHfuFBMw  YVYhnzICPx3tztqw83Mplg  ft-u7hmJk2b-UPdZrL55fw   \n",
       "4  K0X2DplCcYz-GB_Q96G3IQ  CqWXSfo_f5ZWUG-fxAmw3g  r_bcfIdazjqn-y7HP6rAUg   \n",
       "\n",
       "   stars  useful  funny  cool  \\\n",
       "0    4.0       0      0     0   \n",
       "1    3.0       0      0     0   \n",
       "2    5.0       0      0     0   \n",
       "3    2.0       0      0     0   \n",
       "4    1.0       0      0     0   \n",
       "\n",
       "                                                text                 date  \n",
       "0  Pretty good service. Restaurant is on the more...  2019-01-30 22:26:00  \n",
       "1  So I have to give kudos to the lady taking my ...  2019-01-12 04:13:48  \n",
       "2  The ingredients are fresh here and the subs ar...  2019-02-02 20:46:28  \n",
       "3  The coffee is pretty good, when it's available...  2019-02-14 13:24:10  \n",
       "4  Food is BLAND, service is not good. Me and my ...  2019-01-11 18:05:24  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cc54a8",
   "metadata": {},
   "source": [
    "### Creating New Variables\n",
    "\n",
    "We're going to create a dictionary from <tt>biz_df</tt> so that we can efficiently look up the categories and price range for the business corresponding to each of our reviews. The following line sets the index of <tt>biz_df</tt> to the <tt>business_id</tt> field, then converts the whole thing to a dictionary using the \"index\" option for the `to_dict` method. The keys for the resulting dictionary <tt>biz_dict</tt> are business IDs. The values are also dictionaries--i.e., one dictionary per business ID--containing the fields of the original <tt>biz_df</tt>.\n",
    "\n",
    "To add a <tt>categories</tt> column to our new dataframe of reviews, we'll use `map` with a lambda function that simply looks up the value of \"categories\" for each business. Since \"attributes\" is itself a dictionary, we'll create a column for the restaurant price using a similar function that looks up the value for \"RestaurantsPriceRange2\" in the \"attributes\" dictionary--which is inside the dictionary for each business ID, which is inside the overarching dictionary, <tt>biz_dict</tt>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5967b173",
   "metadata": {},
   "outputs": [],
   "source": [
    "biz_dict = biz_df.set_index(\"business_id\").to_dict(\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68829969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Burgerville',\n",
       " 'address': '12785 SW Pacific Hwy',\n",
       " 'city': 'Tigard',\n",
       " 'state': 'OR',\n",
       " 'postal_code': '97223',\n",
       " 'latitude': 45.4276083568,\n",
       " 'longitude': -122.7779190908,\n",
       " 'stars': 3.0,\n",
       " 'review_count': 78,\n",
       " 'is_open': 1,\n",
       " 'attributes': {'BikeParking': 'True',\n",
       "  'RestaurantsAttire': \"u'casual'\",\n",
       "  'BusinessAcceptsCreditCards': 'True',\n",
       "  'RestaurantsTakeOut': 'True',\n",
       "  'GoodForKids': 'True',\n",
       "  'WiFi': \"'free'\",\n",
       "  'RestaurantsGoodForGroups': 'True',\n",
       "  'HasTV': 'False',\n",
       "  'GoodForMeal': \"{'dessert': False, 'latenight': False, 'lunch': True, 'dinner': False, 'brunch': False, 'breakfast': False}\",\n",
       "  'BusinessParking': \"{'garage': False, 'street': False, 'validated': False, 'lot': True, 'valet': False}\",\n",
       "  'Caters': 'False',\n",
       "  'Ambience': \"{'romantic': False, 'intimate': False, 'classy': False, 'hipster': False, 'divey': False, 'touristy': False, 'trendy': False, 'upscale': False, 'casual': True}\",\n",
       "  'NoiseLevel': \"'average'\",\n",
       "  'OutdoorSeating': 'False',\n",
       "  'RestaurantsPriceRange2': '1',\n",
       "  'RestaurantsReservations': 'False',\n",
       "  'Alcohol': \"u'none'\",\n",
       "  'DriveThru': 'True',\n",
       "  'RestaurantsDelivery': 'True'},\n",
       " 'categories': 'Burgers, American (New), Restaurants, Fast Food',\n",
       " 'hours': {'Monday': '0:0-0:0',\n",
       "  'Tuesday': '10:0-22:0',\n",
       "  'Wednesday': '10:0-22:0',\n",
       "  'Thursday': '10:0-18:0',\n",
       "  'Friday': '10:0-22:0',\n",
       "  'Saturday': '10:0-22:0',\n",
       "  'Sunday': '10:0-22:0'}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biz_dict[\"y-MM8_RYgtvgyJojV1RWLg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dcefa94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"categories\"] = df.business_id.map(lambda x: biz_dict[x][\"categories\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "54373852",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"price_tier\"] = df.business_id.map(lambda x: biz_dict[x][\"attributes\"][\"RestaurantsPriceRange2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d929283",
   "metadata": {},
   "source": [
    "Let's check the unique values of <tt>price_tier</tt>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "567f31b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2', '1', '3', '4'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.price_tier.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1480dcf3",
   "metadata": {},
   "source": [
    "We can now use `apply(int)` to convert the column values to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55ca8d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.price_tier = df.price_tier.apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6b07fb37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 3, 4], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.price_tier.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e4099d",
   "metadata": {},
   "source": [
    "### Sampling\n",
    "\n",
    "Now we'll take a sample of the reviews using the built-in `sample` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7d41735d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 20000\n",
    "\n",
    "sample = df.sample(SAMPLE_SIZE)\n",
    "sample.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0bc46ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.drop(columns=[\"index\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b229774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>categories</th>\n",
       "      <th>price_tier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_FD0i3UCDEKJmI1hQJBxbw</td>\n",
       "      <td>UPVNtJBaLt5s5n8_crAQag</td>\n",
       "      <td>TV2FwNhOTdc-0uLvD-DHQg</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I just received my order delivered via Postmat...</td>\n",
       "      <td>2019-09-06 02:18:35</td>\n",
       "      <td>Fast Food, Restaurants, Salad, Pizza</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LNHQzsaI7J3oJc7IXnGT8Q</td>\n",
       "      <td>a---NC4J5BExqVvj2MubLA</td>\n",
       "      <td>gzzl_-bVtlCEyn34WtQ72g</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bubble World has gone down over the years. The...</td>\n",
       "      <td>2019-03-27 02:28:26</td>\n",
       "      <td>Bubble Tea, Restaurants, Taiwanese, Coffee &amp; T...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FgTDclq_60B1KqGGw2Royg</td>\n",
       "      <td>SdMVWxstaq8vML3EBenfAQ</td>\n",
       "      <td>p6RnfILI0jImkLz6uPiSqg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I've passed this restaurant in a small strip m...</td>\n",
       "      <td>2019-07-05 12:49:36</td>\n",
       "      <td>Mediterranean, Restaurants, Halal, Indian</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TmSbJvBacoD2-ai3C3rb2A</td>\n",
       "      <td>IWx9GNcJqK9yUk6gNLoYHQ</td>\n",
       "      <td>lygLAJtC-Oqz-UyCKUQ01A</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Outstanding! Food tasted great, GIANT portIons...</td>\n",
       "      <td>2019-12-11 17:27:31</td>\n",
       "      <td>Restaurants, Chinese</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UdmrtwRa-f0Rfe4W_eBxqg</td>\n",
       "      <td>v6QcUYdONxzc4U6IerCmVw</td>\n",
       "      <td>J6yW_6qMU_UZMJtq6AbNIw</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>One star for poor management skills and OK foo...</td>\n",
       "      <td>2020-02-29 01:19:33</td>\n",
       "      <td>Burgers, American (New), Bars, Restaurants, Ni...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  _FD0i3UCDEKJmI1hQJBxbw  UPVNtJBaLt5s5n8_crAQag  TV2FwNhOTdc-0uLvD-DHQg   \n",
       "1  LNHQzsaI7J3oJc7IXnGT8Q  a---NC4J5BExqVvj2MubLA  gzzl_-bVtlCEyn34WtQ72g   \n",
       "2  FgTDclq_60B1KqGGw2Royg  SdMVWxstaq8vML3EBenfAQ  p6RnfILI0jImkLz6uPiSqg   \n",
       "3  TmSbJvBacoD2-ai3C3rb2A  IWx9GNcJqK9yUk6gNLoYHQ  lygLAJtC-Oqz-UyCKUQ01A   \n",
       "4  UdmrtwRa-f0Rfe4W_eBxqg  v6QcUYdONxzc4U6IerCmVw  J6yW_6qMU_UZMJtq6AbNIw   \n",
       "\n",
       "   stars  useful  funny  cool  \\\n",
       "0    2.0       0      0     0   \n",
       "1    2.0       0      0     0   \n",
       "2    4.0       1      0     0   \n",
       "3    5.0       0      0     0   \n",
       "4    1.0       0      0     0   \n",
       "\n",
       "                                                text                 date  \\\n",
       "0  I just received my order delivered via Postmat...  2019-09-06 02:18:35   \n",
       "1  Bubble World has gone down over the years. The...  2019-03-27 02:28:26   \n",
       "2  I've passed this restaurant in a small strip m...  2019-07-05 12:49:36   \n",
       "3  Outstanding! Food tasted great, GIANT portIons...  2019-12-11 17:27:31   \n",
       "4  One star for poor management skills and OK foo...  2020-02-29 01:19:33   \n",
       "\n",
       "                                          categories  price_tier  \n",
       "0               Fast Food, Restaurants, Salad, Pizza           1  \n",
       "1  Bubble Tea, Restaurants, Taiwanese, Coffee & T...           1  \n",
       "2          Mediterranean, Restaurants, Halal, Indian           2  \n",
       "3                               Restaurants, Chinese           1  \n",
       "4  Burgers, American (New), Bars, Restaurants, Ni...           2  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f49dab",
   "metadata": {},
   "source": [
    "### Preprocessing and n-grams\n",
    "\n",
    "The code provided for preprocessing the reviews is largely the same as the code we've been using. The nested for loop at the end of the next cell is from [here](https://stackoverflow.com/a/52266292). This adds capitalized and fully uppercase versions of each stop word (e.g., \"The\" and \"THE\") to the set of stop words from `spacy`. The second-to-last line of the <tt>preprocess_doc</tt> function definition splits each review on whitespace and keeps each token that is at least two characters and isn't in the set of stop words. That repeats something we do inside the earlier list comprehension involving the spacy language model we've loaded as <tt>nlp</tt>; we do this again because there may be tokens that, after removing non-alphabetic characters, look like stop words or are now a single character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d257c375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_ordinal_nums(word: str) -> str:\n",
    "    ord_num_reg = r\"\\d+[(st)(nd)(rd)(th)]\"\n",
    "    try:\n",
    "        if any(re.findall(ord_num_reg, word)):\n",
    "            word = re.sub(\"[(st)(nd)(rd)(th)]\", \"\", word)\n",
    "            word = num2words(word, lang=\"en\", to=\"ordinal\")\n",
    "            \n",
    "        return word\n",
    "    \n",
    "    except:\n",
    "        \n",
    "        return word\n",
    "\n",
    "\n",
    "def preprocess_doc(doc: str) -> str:\n",
    "    \"\"\"\n",
    "    Tokenize, lemmatize, remove stop words, \n",
    "    remove non-alphabetic characters.\n",
    "    \"\"\"\n",
    "    doc = unidecode(str(doc))\n",
    "    doc = contractions.fix(doc)\n",
    "    doc = [word.lemma_ for word in nlp(doc) if not word.is_stop and (len(word.text) > 1)]\n",
    "    doc = \" \".join([fix_ordinal_nums(word) for word in doc])\n",
    "    doc = re.sub(\"[^a-z]\", \" \", doc.lower())\n",
    "    doc = \" \".join([word for word in doc.split() if len(word) > 1 and word not in STOP_WORDS])\n",
    "    \n",
    "    return re.sub(\"\\s+\", \" \", doc).strip()\n",
    "    \n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"parser\"])\n",
    "\n",
    "# https://stackoverflow.com/a/52266292\n",
    "for word in STOP_WORDS:\n",
    "    for w in (word, word.capitalize(), word.upper()):\n",
    "        lex = nlp.vocab[w]\n",
    "        lex.is_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2e9a3c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sample[\"preprocessed\"] = [preprocess_doc(doc) for doc in sample.text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "17d8bb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ngram_model(docs: list, min_count: int=5, inc_trigrams: bool=True) -> list:\n",
    "    \"\"\"Returns documents with n-grams joined by underscores\"\"\"\n",
    "    docs = [doc for doc in docs if doc] # the \"if doc\" condition removes empty strings (docs with no words)\n",
    "    bigram_model = Phrases(docs, min_count=min_count)\n",
    "    ngrams = bigram_model[docs]\n",
    "    ngrams = list(ngrams)\n",
    "    if inc_trigrams:\n",
    "        trigram_model = Phrases(ngrams, min_count=min_count)\n",
    "        ngrams = trigram_model[ngrams]\n",
    "        ngrams = list(ngrams)\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "52411a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.17 s\n"
     ]
    }
   ],
   "source": [
    "sample.preprocessed = sample.preprocessed.apply(str.split)\n",
    "%time sample[\"ngrams\"] = train_ngram_model(sample.preprocessed, min_count=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fd303972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>categories</th>\n",
       "      <th>price_tier</th>\n",
       "      <th>preprocessed</th>\n",
       "      <th>ngrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_FD0i3UCDEKJmI1hQJBxbw</td>\n",
       "      <td>UPVNtJBaLt5s5n8_crAQag</td>\n",
       "      <td>TV2FwNhOTdc-0uLvD-DHQg</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I just received my order delivered via Postmat...</td>\n",
       "      <td>2019-09-06 02:18:35</td>\n",
       "      <td>Fast Food, Restaurants, Salad, Pizza</td>\n",
       "      <td>1</td>\n",
       "      <td>[receive, order, deliver, postmates, pizza, pe...</td>\n",
       "      <td>[receive, order, deliver, postmates, pizza, pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LNHQzsaI7J3oJc7IXnGT8Q</td>\n",
       "      <td>a---NC4J5BExqVvj2MubLA</td>\n",
       "      <td>gzzl_-bVtlCEyn34WtQ72g</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bubble World has gone down over the years. The...</td>\n",
       "      <td>2019-03-27 02:28:26</td>\n",
       "      <td>Bubble Tea, Restaurants, Taiwanese, Coffee &amp; T...</td>\n",
       "      <td>1</td>\n",
       "      <td>[bubble, world, year, menu, extensive, new, bu...</td>\n",
       "      <td>[bubble, world, year, menu, extensive, new, bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FgTDclq_60B1KqGGw2Royg</td>\n",
       "      <td>SdMVWxstaq8vML3EBenfAQ</td>\n",
       "      <td>p6RnfILI0jImkLz6uPiSqg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I've passed this restaurant in a small strip m...</td>\n",
       "      <td>2019-07-05 12:49:36</td>\n",
       "      <td>Mediterranean, Restaurants, Halal, Indian</td>\n",
       "      <td>2</td>\n",
       "      <td>[pass, restaurant, small, strip, mall, week, n...</td>\n",
       "      <td>[pass, restaurant, small, strip_mall, week, no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TmSbJvBacoD2-ai3C3rb2A</td>\n",
       "      <td>IWx9GNcJqK9yUk6gNLoYHQ</td>\n",
       "      <td>lygLAJtC-Oqz-UyCKUQ01A</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Outstanding! Food tasted great, GIANT portIons...</td>\n",
       "      <td>2019-12-11 17:27:31</td>\n",
       "      <td>Restaurants, Chinese</td>\n",
       "      <td>1</td>\n",
       "      <td>[outstanding, food, taste, great, giant, porti...</td>\n",
       "      <td>[outstanding, food, taste, great, giant, porti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UdmrtwRa-f0Rfe4W_eBxqg</td>\n",
       "      <td>v6QcUYdONxzc4U6IerCmVw</td>\n",
       "      <td>J6yW_6qMU_UZMJtq6AbNIw</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>One star for poor management skills and OK foo...</td>\n",
       "      <td>2020-02-29 01:19:33</td>\n",
       "      <td>Burgers, American (New), Bars, Restaurants, Ni...</td>\n",
       "      <td>2</td>\n",
       "      <td>[star, poor, management, skill, ok, food, salm...</td>\n",
       "      <td>[star, poor, management, skill, ok, food, salm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  _FD0i3UCDEKJmI1hQJBxbw  UPVNtJBaLt5s5n8_crAQag  TV2FwNhOTdc-0uLvD-DHQg   \n",
       "1  LNHQzsaI7J3oJc7IXnGT8Q  a---NC4J5BExqVvj2MubLA  gzzl_-bVtlCEyn34WtQ72g   \n",
       "2  FgTDclq_60B1KqGGw2Royg  SdMVWxstaq8vML3EBenfAQ  p6RnfILI0jImkLz6uPiSqg   \n",
       "3  TmSbJvBacoD2-ai3C3rb2A  IWx9GNcJqK9yUk6gNLoYHQ  lygLAJtC-Oqz-UyCKUQ01A   \n",
       "4  UdmrtwRa-f0Rfe4W_eBxqg  v6QcUYdONxzc4U6IerCmVw  J6yW_6qMU_UZMJtq6AbNIw   \n",
       "\n",
       "   stars  useful  funny  cool  \\\n",
       "0    2.0       0      0     0   \n",
       "1    2.0       0      0     0   \n",
       "2    4.0       1      0     0   \n",
       "3    5.0       0      0     0   \n",
       "4    1.0       0      0     0   \n",
       "\n",
       "                                                text                 date  \\\n",
       "0  I just received my order delivered via Postmat...  2019-09-06 02:18:35   \n",
       "1  Bubble World has gone down over the years. The...  2019-03-27 02:28:26   \n",
       "2  I've passed this restaurant in a small strip m...  2019-07-05 12:49:36   \n",
       "3  Outstanding! Food tasted great, GIANT portIons...  2019-12-11 17:27:31   \n",
       "4  One star for poor management skills and OK foo...  2020-02-29 01:19:33   \n",
       "\n",
       "                                          categories  price_tier  \\\n",
       "0               Fast Food, Restaurants, Salad, Pizza           1   \n",
       "1  Bubble Tea, Restaurants, Taiwanese, Coffee & T...           1   \n",
       "2          Mediterranean, Restaurants, Halal, Indian           2   \n",
       "3                               Restaurants, Chinese           1   \n",
       "4  Burgers, American (New), Bars, Restaurants, Ni...           2   \n",
       "\n",
       "                                        preprocessed  \\\n",
       "0  [receive, order, deliver, postmates, pizza, pe...   \n",
       "1  [bubble, world, year, menu, extensive, new, bu...   \n",
       "2  [pass, restaurant, small, strip, mall, week, n...   \n",
       "3  [outstanding, food, taste, great, giant, porti...   \n",
       "4  [star, poor, management, skill, ok, food, salm...   \n",
       "\n",
       "                                              ngrams  \n",
       "0  [receive, order, deliver, postmates, pizza, pe...  \n",
       "1  [bubble, world, year, menu, extensive, new, bu...  \n",
       "2  [pass, restaurant, small, strip_mall, week, no...  \n",
       "3  [outstanding, food, taste, great, giant, porti...  \n",
       "4  [star, poor, management, skill, ok, food, salm...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f590588",
   "metadata": {},
   "source": [
    "### Saving the Sample\n",
    "\n",
    "We'll save our sample to disk, keeping only the <tt>stars</tt>, <tt>text</tt>, <tt>ngrams</tt>, <tt>price_tier</tt>, <tt>categories</tt>, and <tt>date</tt> columns.\n",
    "\n",
    "Notebook 13b has a line that will prompt you to upload a file. Upload the file we create here, <tt>yelp_reviews_sample_for_notebook13b.json</tt>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a5edc65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[[\"stars\", \"text\", \"ngrams\", \"price_tier\", \"categories\", \"date\"]].to_json(\"yelp_reviews_sample_for_notebook13b.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
