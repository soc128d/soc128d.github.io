{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sociology 128D: Mining Culture Through Text Data: Introduction to Social Data Science â€“ Summer '22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 5: Document Similarity \n",
    "\n",
    "In this notebook, we're going to go a bit farther with vector semantics, which is one of the main approaches we'll use in this class and which has had an enormous influence in cultural sociology. Specifically, we are going to build on Notebook 3 by using document-term matrices and tf-idf weighting as a basis for directly measuring how similar or dissimilar documents are.\n",
    "\n",
    "Regarding the exercises at the end, don't worry if you aren't a history buff. The exercises are just meant to reinforce how text data can be used for social inquiry. \n",
    "\n",
    "Please download the [State of the Union Corpus (1790-2018)](https://www.kaggle.com/rtatman/state-of-the-union-corpus-1989-2017), which was posted to Kaggle by Rachael Tatman and Liling Tan. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "\n",
    "sns.set_theme(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Cleaning the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to load the data a bit like we did in Notebook 3. First, we're going to create a `list` called <tt>text_files</tt> using the [`filter() method`](https://www.geeksforgeeks.org/filter-in-python/). `filter()` uses a [lambda function](https://www.geeksforgeeks.org/python-lambda-anonymous-functions-filter-map-reduce/) to filter out unwanted elements of an iterable (such as a list). The function and the iterable are the two parts of the call to `filter()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_files = list(filter(lambda x: x.endswith(\".txt\"), os.listdir(\"data/sotu\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_files[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this application, ```lambda x: x.endswith(\".txt\")``` returns <tt>True</tt> if something is a string and ends with \".txt\" or <tt>False</tt> otherwise.\n",
    "\n",
    "The second part, ```os.listdir(\"sotu\")```, uses the [`os` module's](https://www.geeksforgeeks.org/os-module-python-examples/) `listdir()` method to return a list of filenames in the directory.\n",
    "\n",
    "Our call to `filter()` checks whether each filename in that directory ends with \".txt\" and returns only the files for which that is true. We then cast the result as a `list`.\n",
    "\n",
    "The result, <tt>text_files</tt>, is a list of filenames in the directory \"sotu\" that end with \".txt\"--but the file names don't include the full path from our working directory to the files. We need to add the directory \"sotu\" to the filenames to access the files.\n",
    "\n",
    "We're going to use [`os.path.join()`](https://www.geeksforgeeks.org/python-os-path-join-method/) to create a list of file paths. We'll call this list <tt>address_paths</tt> because it's a list of the file paths for State of the Union Addresses (stored as files ending in .txt). We'll use a list comprehension, but this is the same as looping through <tt>text_files</tt> with a for loop, using `os.path.join()`, and appending the result to the list we are creating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_paths = [os.path.join(\"data/sotu/\", f) for f in text_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(address_paths[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to use these file paths to create a data frame with the text of each State of the Union as well as the president and year. The function <tt>return_sotu_name_year_text()</tt> accepts just one argument, a file path.\n",
    "\n",
    "The file path points us to the text, but the *filename* includes the president and the year joined by an underscore.\n",
    "\n",
    "> Adams_1797.txt\n",
    "\n",
    "Since the filename is just a string, we can easily associate the text of each State of the Union with the corresponding president and year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_sotu_name_year_text(f: str):\n",
    "    \"\"\"\n",
    "    Return the name, year, and text of a SOTU.\n",
    "    \"\"\"\n",
    "    doc = open(f, \"r\").read().strip()\n",
    "    f = os.path.split(f)[-1]\n",
    "    f = f.replace(\".txt\", \"\")\n",
    "    pres, year = f.split(\"_\")\n",
    "    \n",
    "    return pres, year, doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "The line\n",
    "    \n",
    "```python\n",
    "doc = open(f, \"r\").read().strip()\n",
    "```\n",
    "opens the file path <tt>f</tt>, reads the full file into memory as a string, and strips whitespace like linebreaks from the ends.<br>\n",
    "\n",
    "```python\n",
    "f = os.path.split(f)[-1]\n",
    "```\n",
    "\n",
    "replaces the file path we've stored as the variable <tt>f</tt> with the last part of the file path, in this case the filename ending in .txt, by splitting the file path and taking the last element by using the index -1.\n",
    "\n",
    "```python\n",
    "pres, year = f.split(\"_\")\n",
    "```\n",
    "creates the variables <tt>pres</tt> and <tt>year</tt> by splitting the filename <tt>f</tt> on underscores.\n",
    "</div>\n",
    "\n",
    "Now we can load the data. First, we create a dataframe with only one column: the file path. Next, we apply our function <tt>return_sotu_name_year_text()</tt> to each row's file path, creating three new columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(address_paths, columns = [\"file_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"president\", \"year\", \"text\"]] = df.file_path.apply(lambda x: pd.Series(return_sotu_name_year_text(x)))\n",
    "df.drop(columns = [\"file_path\"], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also drop the original column containing the file path. Now we have a dataframe with just the president, year, and text for each State of the Union."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we sort the dataframe by year, remove any rows without actual speeches (i.e., where the <tt>text</tt> column is an empty string), identify any missing years, and reset the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"text\"] != \"\"]\n",
    "df = df.astype({\"year\": int})\n",
    "df.year.min(), df.year.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in range(1791,2019) if i not in df.year.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=\"year\", inplace=True)\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we want to make sure that we're distinguishing between presidents with the same last names. There were two Harrisons, but William Henry Harrison didn't live long enough to give a State of the Union address. Neither did James A. Garfield. Since Grover Cleveland counts twice, that gives us 42 unique presidents who had given a State of the Union address in the time period covered by the corpus, which stops in 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.president = np.where(df.president.eq(\"Adams\") & df[\"year\"].gt(1800), \"Adams2\", df.president)\n",
    "df.president = np.where(df.president.eq(\"Bush\") & df[\"year\"].gt(2000), \"Bush2\", df.president)\n",
    "df.president = np.where(df.president.eq(\"Johnson\") & df[\"year\"].gt(1900), \"Johnson2\", df.president)\n",
    "df.president = np.where(df.president.eq(\"Roosevelt\") & df[\"year\"].gt(1930), \"Roosevelt2\", df.president)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.president.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.president.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a `dict` and the `.apply()` method to create a column for the party of the president who gave the speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_dict = {\n",
    "    'Washington': \"Unaffiliated\", \n",
    "    'Adams': \"Federalist\", \n",
    "    'Jefferson': \"Democratic-Republican\", \n",
    "    'Madison': \"Democratic-Republican\", \n",
    "    'Monroe': \"Democratic-Republican\", \n",
    "    'Adams2': \"Democratic-Republican\", \n",
    "    'Jackson': \"Democrat\", \n",
    "    'Buren': \"Democrat\", \n",
    "    'Tyler': \"Whig\", \n",
    "    'Polk': \"Democrat\", \n",
    "    'Taylor': \"Whig\", \n",
    "    'Fillmore': \"Whig\", \n",
    "    'Pierce': \"Democrat\", \n",
    "    'Buchanan': \"Democrat\", \n",
    "    'Lincoln': \"Republican\", \n",
    "    'Johnson': \"Democrat\", \n",
    "    'Grant': \"Republican\", \n",
    "    'Hayes': \"Republican\", \n",
    "    'Arthur': \"Republican\", \n",
    "    'Cleveland': \"Democrat\", \n",
    "    'Harrison': \"Republican\", \n",
    "    'McKinley': \"Republican\", \n",
    "    'Roosevelt': \"Republican\", \n",
    "    'Taft': \"Republican\", \n",
    "    'Wilson': \"Democrat\", \n",
    "    'Harding': \"Republican\", \n",
    "    'Coolidge': \"Republican\", \n",
    "    'Hoover': \"Republican\", \n",
    "    'Roosevelt2': \"Democrat\", \n",
    "    'Truman': \"Democrat\", \n",
    "    'Eisenhower': \"Republican\", \n",
    "    'Kennedy': \"Democrat\", \n",
    "    'Johnson2': \"Democrat\", \n",
    "    'Nixon': \"Republican\", \n",
    "    'Ford': \"Republican\", \n",
    "    'Carter': \"Democrat\", \n",
    "    'Reagan': \"Republican\", \n",
    "    'Bush': \"Republican\", \n",
    "    'Clinton': \"Democrat\", \n",
    "    'Bush2': \"Republican\", \n",
    "    'Obama': \"Democrat\", \n",
    "    'Trump': \"Republican\"\n",
    "}\n",
    "\n",
    "df[\"party\"] = df.president.apply(lambda x: party_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"party\", \"year\"]].groupby(\"party\").count() # number of speeches by party in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"president\", \"year\"]].groupby(\"president\").count() # number of speeches by each pres in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_post(post: str) -> str:\n",
    "    \"\"\"\n",
    "    Tokenize, lemmatize, remove stop words, \n",
    "    remove non-alphabetic characters.\n",
    "    \"\"\"\n",
    "    post = \" \".join([word.lemma_ for word in nlp(post) if not word.is_stop])\n",
    "    post = re.sub(\"[^a-z]\", \" \", post.lower())\n",
    "    \n",
    "    return re.sub(\"\\s+\", \" \", post).strip()\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object we call <tt>nlp</tt> is a language model from [spaCy](https://spacy.io/). It does part-of-speech tagging, named entity recognition, and more. `disable=[\"ner\"]` tells it not to perform named entity recognition. Turning things off might speed it up!\n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "The function <tt>preprocess_post()</tt> is equivalent to the following:\n",
    "\n",
    "```python\n",
    "def preprocess_post(post: str) -> str:\n",
    "    \"\"\"\n",
    "    Tokenizes and returns the lowercase lemmas of\n",
    "    tokens that are not stop words, minus any \n",
    "    non-alphabetic characters\n",
    "    \"\"\"\n",
    "    words = []\n",
    "    for word in nlp(post): # each \"word\" in nlp(post) has been part-of-speech tagged, etc.\n",
    "        if not word.is_stop: # \".is_stop\" checks whether spacy has determined it's a stop word\n",
    "            words.append(word.lemma_) # adding the lemma of the word, not the word itself, to the list\n",
    "    post = \" \".join(words) # converting the list of words to a string variable separated by spaces\n",
    "    post = post.lower() # make everything lowercase\n",
    "    post = re.sub(\"[^a-z]\", \" \", post) # now we replace non-alphabetic chars with spaces\n",
    "    post = re.sub(\"\\s+\", \" \", post) # now we replace long stretches of whitespace with a single space\n",
    "    post = post.strip() # now we strip whitespace from the edges\n",
    "    \n",
    "    return post\n",
    "```\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df[\"preprocessed\"] = df.text.apply(preprocess_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(\"df_with_preprocessed_sotu.json\")\n",
    "df = pd.read_json(\"df_with_preprocessed_sotu.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Document-Term Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting a corpus of documents to a `document-term matrix` is a core step for many NLP tasks. We saw how to do that in Notebook 3, but we'll review it now before introducing a faster way to complete this step.\n",
    "\n",
    "We'll start by getting the number of times each *type* (unique word) occurs in the entire corpus. We'll save this as a `dict` called <tt>term_frequencies</tt>, which we'll create using the [`Counter()` method](https://www.geeksforgeeks.org/counters-in-python-set-1/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_frequencies = Counter(\" \".join(df[\"preprocessed\"]).split())\n",
    "vocabulary = list(term_frequencies.keys())\n",
    "print(f\"There are {len(vocabulary):,} unique words in the corpus.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Let's break this down a bit:\n",
    "\n",
    "```python\n",
    "\" \".join(df[\"preprocessed\"]).split()\n",
    "```\n",
    "\n",
    "\n",
    "joins each of the preprocessed speeches with a single space, creating one big document with all of the *tokens* in the entire corpus. This would be a single string. The `str.split()` method then splits that string on whitespace (like spaces), returning a `list` containing all the tokens.\n",
    "\n",
    "We then use the `Counter()` method to count the number of times each type occurs in that list, saving it as <tt>term_frequencies</tt>.\n",
    "\n",
    "```python\n",
    "vocabulary = list(term_frequencies.keys())\n",
    "```\n",
    "\n",
    "accesses the keys (types) and casts the result as a `list`, giving us a list of the unique words.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at some of the most frequent words. Here, we create a `list` called <tt>tups</tt> (short for tuples) by accessing the `.items()` from <tt>term_frequencies</tt>. Each \"item\" is a tuple like <tt>(key, value)</tt>, where the key and value are the type and count. We sort this list using a lambda function that checks the value at index 1. The value at index 1 of each tuple is the number of times the word occurs in the corpus. This means that\n",
    "\n",
    "```python\n",
    "key = lambda x: x[1]\n",
    "```\n",
    "\n",
    "says we want to sort by the frequencies. We also set `reverse=True` to get a list in order from most frequent to least frequent. We then display the first ten using `tups[:10]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tups = sorted(list(term_frequencies.items()), key=lambda x: x[1], reverse=True)\n",
    "tups[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we filter the vocabulary to exclude words that occur only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = list(filter(lambda x: term_frequencies[x] > 1, vocabulary))\n",
    "print(f\"{len(vocabulary):,} unique words occur more than once.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define a function that accepts a string as an argument and returns a version of that string without any duplicate words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_of_types(document: str) -> str:\n",
    "    \"\"\"\n",
    "    Returns a string with all duplicates of words removed\n",
    "    \"\"\"\n",
    "\n",
    "    return \" \".join(set(document.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function <tt>set_of_types()</tt> uses the `str.split()` method to split the speech (a string) on whitespace, casts it as a `set()` (removing any duplicates), then uses the `.join()` method to join the tokens into a single string again using whitespace.\n",
    "\n",
    "Now we create a column called <tt>types</tt> by applying this function to the preprocessed text, row by row. This creates a copy of each speech without any duplicate words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"types\"] = df.preprocessed.apply(set_of_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do we do that? It's just a convenient way to count the number of documents each word occurs in. Just like the code we used to create <tt>term_frequencies</tt>, the code to create <tt>document_frequencies</tt> first joins the <tt>types</tt> with a single space, creating one big document. It then uses `str.split()` to convert that giant document into a list of tokens, and then uses the `Counter()` method to count how many times each type occurs. \n",
    "\n",
    "We can get rid of the <tt>types</tt> column. It has served its purpose: helping avoid going word by word through each document to get the number of documents in which each word occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_frequencies = Counter(\" \".join(df.types).split())\n",
    "df.drop(columns=[\"types\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words that occur in only one document don't give us a lot of information, so we'll filter them out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = list(filter(lambda x: document_frequencies[x] > 1, vocabulary))\n",
    "print(f\"The vocabulary now has {len(vocabulary):,} words.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're almost ready to create the `document-term matrix`. We'll create a copy of our dataframe and call it <tt>dtm</tt> (for \"document-term matrix\"). We're only going to keep the column with the preprocessed text. We're also going to convert this from a string for each speech to a list of tokens for each speech using `str.split()` and then rename the column \"<preprocessed\\>\" somewhat arbitrarily; we're about to create a column for each unique word, and while we might not expect \"preprocessed\" to be in the vocabulary, it's good practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = copy.copy(df)\n",
    "dtm.preprocessed = dtm.preprocessed.apply(str.split)\n",
    "dtm = dtm[[\"preprocessed\"]]\n",
    "dtm.rename(columns={\"preprocessed\": \"<preprocessed>\"}, inplace = True)\n",
    "dtm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to create a column for each word in the vocabulary. Each row still corresponds to a State of the Union, and the value for each cell will be the number of times that word occurs in that (preprocessed) speech. Since we've converted the preprocessed text to a list, we can use the `.count()` method to get the number of times each word in the vocabulary occurs in each document.\n",
    "\n",
    "The function <tt>term_frequency()</tt> uses a list comprehension and returns a list of word counts for each speech. We can then create the columns with the counts for each word. Next, we drop the \"<preprocessed\\>\" column because we no longer need the text anymore for the document-term matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_frequency(doc: list, vocab: list) -> list:\n",
    "    \"\"\"\n",
    "    Returns counts of each term in a list\n",
    "    \"\"\"\n",
    "    \n",
    "    return [doc.count(term) for term in vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "dtm_counts = dtm[\"<preprocessed>\"].apply(lambda x: pd.Series(term_frequency(x, vocabulary)))\n",
    "dtm_counts.rename(mapper={i:vocabulary[i] for i in range(len(vocabulary))}, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_counts.to_json(\"dtm_counts.json\")\n",
    "dtm_counts = pd.read_json(\"dtm_counts.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Faster Way: CountVectorizer\n",
    "\n",
    "We can do this much more quickly with `scikit-learn's` [`CountVectorizer()` method](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html).\n",
    "\n",
    "The argument `min_df=2` excludes words that occur in fewer than two documents.\n",
    "\n",
    "Let's compare the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "count_vectorizer = CountVectorizer(min_df=2)\n",
    "counts = count_vectorizer.fit_transform(df[\"preprocessed\"])\n",
    "counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use `pd.DataFrame.sparse.from_spmatrix()` to convert the result to a dataframe.\n",
    "\n",
    "The vocabulary is in a different order, and it's 25 columns narrower. Let's see what's missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame.sparse.from_spmatrix(counts, columns=count_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(new_df.to_numpy(), columns=new_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = list(set(dtm_counts.columns).difference(set(new_df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(diffs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`CountVectorizer()` has removed single characters from the vocabulary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This brings us to a few of the key intuitions of text analysis. We now have **vectors** instead of strings as representations of the speeches, and these vectors can be compared quanitatively. More specifically, the documents can now be compared quantitatively as if they were points in a high-dimensional space.\n",
    "\n",
    "Let's start with a simple case of a vocabulary of two words. You can assign different words to <tt>keyword1</tt> and <tt>keyword2</tt> below, and documents are selected at random. We're going to show where documents are in a *two*-dimensional space using counts of these two words. The function <tt>plot_distances()</tt> handles that for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distances(dtm, doc1_idx: int, doc2_idx: int, keyword1: str, keyword2: str, extend=False, cosine=False):\n",
    "    \"\"\"\n",
    "    Plots an arrow illustrating the distance between two\n",
    "    2D \"word vectors\" based on term frequencies\n",
    "    \"\"\"\n",
    "    x1 = dtm.loc[doc1_idx, keyword1]\n",
    "    y1 = dtm.loc[doc1_idx, keyword2]\n",
    "    x2 = dtm.loc[doc2_idx, keyword1]\n",
    "    y2 = dtm.loc[doc2_idx, keyword2]\n",
    "    \n",
    "    doc1 = min([[x1, y1], [x2, y2]], key=lambda x: np.sqrt(x[0]**2 + x[1]**2))\n",
    "    doc2 = max([[x1, y1], [x2, y2]], key=lambda x: np.sqrt(x[0]**2 + x[1]**2))\n",
    "    \n",
    "    if extend==True:\n",
    "        doc3 = [doc2[0]*2, doc2[1]*2]\n",
    "        plt.xlim(0, max(x1, x2, doc3[0])*1.2)\n",
    "        plt.ylim(0, max(y1, y2, doc3[1])*1.2)\n",
    "        plt.text(x = doc3[0], y = doc3[1], s = \"Doc 3\")\n",
    "        plt.arrow(doc1[0], doc1[1], doc3[0]-doc1[0], doc3[1]-doc1[1], width=0.5, length_includes_head=True)\n",
    "    else:\n",
    "        plt.xlim(0, max(x1, x2) * 1.2)\n",
    "        plt.ylim(0, max(y1, y2) * 1.2)\n",
    "    plt.arrow(doc1[0], doc1[1], doc2[0]-doc1[0], doc2[1]-doc1[1], width=0.5, length_includes_head=True)\n",
    "    plt.text(x = doc1[0], y = doc1[1], s = \"Doc 1\")\n",
    "    plt.text(x = doc2[0], y = doc2[1], s = \"Doc 2\")\n",
    "    plt.xlabel(f'Frequecy of \"{keyword1}\"')\n",
    "    plt.ylabel(f'Frequency of \"{keyword2}\"')\n",
    "    \n",
    "    print(f\"Document 1 features '{keyword1}' {doc1[0]} times and '{keyword2}' {doc1[1]} times.\")\n",
    "    print(f\"Document 2 features '{keyword1}' {doc2[0]} times and '{keyword2}' {doc2[1]} times.\")\n",
    "    print(f\"Documents 1 and 2 are {euclidean_distances([doc1], [doc2])[0][0]:.1f} units apart in this 2D space.\")\n",
    "\n",
    "    if extend==True:\n",
    "        print(f\"\\nDocument 3 features '{keyword1}' {doc3[0]} times and '{keyword2}' {doc3[1]} times.\")\n",
    "        print(f\"Documents 1 and 3 are {euclidean_distances([doc1], [doc3])[0][0]:.1f} units apart in this 2D space.\")\n",
    "        if cosine==True:\n",
    "            print(f\"\\nDocuments 1 and 2 have a cosine similarity of {cosine_similarity([doc1], [doc2])[0][0]:.2f}.\")\n",
    "            print(f\"Documents 1 and 3 have a cosine similarity of {cosine_similarity([doc1], [doc3])[0][0]:.2f}.\")\n",
    "            print(f\"Documents 2 and 3 have a cosine similarity of {cosine_similarity([doc2], [doc3])[0][0]:.2f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1_idx = np.random.randint(0, dtm.shape[0])\n",
    "doc2_idx = np.random.randint(0, dtm.shape[0])\n",
    "\n",
    "keyword1 = \"people\"\n",
    "keyword2 = \"law\"\n",
    "\n",
    "plot_distances(dtm_counts, doc1_idx, doc2_idx, keyword1, keyword2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This arrow represents the distance between the two documents in this two-dimensional space, and we can calculate the length of the arrow directly using the Pythagorean theorem. This gives us the [Euclidean distance](https://en.wikipedia.org/wiki/Euclidean_distance) between the points.\n",
    "\n",
    "If we make the assumption that the meaning of the documents is related to the distribution of words in them, then we can make the additional assumption that the distance between the points is related to how semantically similar the documents are. In other words, we might assume that two documents close together mean something similar, whereas documents farther apart are less likely to mean (or be about) the same thing.\n",
    "\n",
    "What about document length, though?\n",
    "\n",
    "Consider the (contrived) example below. Document 3 is identical to Document 2, but twice as long. It's farther from Document 1, but it's in the exact same direction as Document 2 from the origin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1_idx = np.random.randint(0, dtm.shape[0])\n",
    "doc2_idx = np.random.randint(0, dtm.shape[0])\n",
    "\n",
    "keyword1 = \"people\"\n",
    "keyword2 = \"law\"\n",
    "\n",
    "plot_distances(dtm_counts, doc1_idx, doc2_idx, keyword1, keyword2, extend=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use Euclidean distance as our measure of similarity, this makes it look like Document 3 is much less similar to Document 1 than Document 2 is to Document 1, and like Documents 2 and 3 are not very similar. Euclidean distance is a problem in this case.\n",
    "\n",
    "We can use [cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity) instead. Whereas Euclidean distance measures the length of the arrow between the two points, cosine similarity takes into account the *angle*. Document 3 is longer than Document 2, but it has the same proportions of the keywords.\n",
    "\n",
    "If we use cosine, two important points emerge:\n",
    "1. The similarity of Document 2 and Document 3 will be 1.0\n",
    "2. The similarity of Document 1 to Document 2 will be the same as the similarity of Document 1 to Document 3\n",
    "\n",
    "These are both desirable because Document 2 and 3 only differ in length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1_idx = np.random.randint(0, dtm.shape[0])\n",
    "doc2_idx = np.random.randint(0, dtm.shape[0])\n",
    "\n",
    "keyword1 = \"people\"\n",
    "keyword2 = \"law\"\n",
    "\n",
    "plot_distances(dtm_counts, doc1_idx, doc2_idx, keyword1, keyword2, extend=True, cosine=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use these measures beyond this two-dimensional case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-idf Revisited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In Section 6.2...we developed the notion of a document vector that captures the relative importance of the terms in a document. The representation of a set of documents as vectors in a common vector space is known as the vector space model and is fundamental to a host of information retrieval (IR) operations including scoring documents on a query, document classification, and document clustering.\n",
    "<br><br>    [Manning, Raghavan, & Schutze (2008, p. 110)](https://nlp.stanford.edu/IR-book/information-retrieval-book.html)\n",
    "\n",
    "In Notebook 3, we also encountered tf-idf weighting. The key idea is that having rare things in common is more informative than having common things in common. It is not terribly informative if two documents share really common words. Inverse document frequency (idf) weighting helps us assign less importance to words that appear in many documents. We also experimented a bit with weighting the frequencies of terms within documents by logging them. There are [many ways to calculate term frequency and inverse document frequency](https://en.wikipedia.org/wiki/SMART_Information_Retrieval_System).\n",
    "\n",
    "`sklearn` does offer the most flexibility in terms of weighting systems, but it does make tf-idf weighting fast. If we want to calculate a document-term matrix and apply tf-idf weighting, we can use [`sklearn's TfidfVectorizer()`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(min_df=2, sublinear_tf=True) # sublinear_tf logs the term frequencies\n",
    "tfidf = tfidf_vectorizer.fit_transform(df[\"preprocessed\"])\n",
    "tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df = pd.DataFrame.sparse.from_spmatrix(tfidf, columns=tfidf_vectorizer.get_feature_names_out())\n",
    "tfidf_df = pd.DataFrame(tfidf_df.to_numpy(), columns=tfidf_df.columns)\n",
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Similar Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_similar(query: str, num_matches: int=1, cosine: bool=True) -> list:\n",
    "    \"\"\"\n",
    "    Preprocess a query and find `num_matches` using tf-idf and either cosine or Euclidean distance\n",
    "    \"\"\"\n",
    "    query = preprocess_post(query)\n",
    "    query = tfidf_vectorizer.transform([query])\n",
    "    \n",
    "    if cosine==True:\n",
    "        matches = [(idx, cosine_similarity(query, np.array(post).reshape(1,-1))[0][0]) for idx, post in tfidf_df.iterrows()]\n",
    "    else:\n",
    "        matches = [(idx, euclidean_distances(query, np.array(post).reshape(1,-1))[0][0]) for idx, post in tfidf_df.iterrows()]\n",
    "    \n",
    "    matches = sorted(matches, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return matches[:num_matches]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure everything is working. The most similar document to any given speech should be the speech itself!\n",
    "\n",
    "Here's a random selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = df.sample(1)[\"text\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(query[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get the tf-idf-weighted version of it. Notably, *these weights are based on the document frequencies in the original corpus*. While the resulting vector represents the new query, the relative importance assigned to each word means we have already incorporated information from the other documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_tfidf = tfidf_vectorizer.transform([query])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's find the most similar speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_most_similar(query, num_matches=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[55].text[:500]) # the speech is selected at random, so you will need to change the index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compare the documents to new documents, for example to other figures who influenced social thought. This quote is an arbitrary example (but comes from Simmel's essay \"Fashion\" in *Georg Simmel on Individuality and Social Forms*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"The charm of imitation in the first place is to be found in the fact that it makes possible an expedient \n",
    "test of power, which, however, requires no great personal or creative application, but is displayed easily and \n",
    "smoothly, because its content is a given quantity. We might define it as the child of thought and thoughtlessness. \n",
    "It affords the pregnant possibility of continually extending the greatest creations of the human spirit, without the \n",
    "aid of the forces which were originally the very condition of their birth. Imitation, furthermore, gives to the \n",
    "individual the satisfaction of not standing alone in his actions. Whenever we imitate, we transfer not only the \n",
    "demand for creative activity, but also the responsibility for the action from ourselves to another. Thus the \n",
    "individual is freed from the worry of choosing and appears simply as a creature of the group, as a vessel of the \n",
    "social contents...\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_most_similar(query, num_matches=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"President: {df.loc[179].president}\")\n",
    "print(f\"Year: {df.loc[179].year}\")\n",
    "print(f\"Party: {df.loc[179].party}\")\n",
    "print(f\"Snippet of text:\\n\\n{df.loc[179].text[:500]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Similarity as an Outcome Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ability to position documents in a shared vector space also means we can treat document similarity as an outcome. We can compare many things (like an entire corpus!) to a single document, calculating the similarity (or distance) for each comparison. We can look at relationships between document similarity and other variables.\n",
    "\n",
    "### Example 1: Similarity to First Document\n",
    "Let's pick an obvious starting point: the first document. We'll calculate the similarity between each subsequent document and the first document and then observe trends in that measure over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = df.loc[0].text # the text of the first row in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(query[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already have the vector. Let's assign it to a variable called <tt>query_tfidf</tt> and check the `shape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_tfidf = tfidf_df.loc[0]\n",
    "query_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df.loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we retrieve it using `.loc` and the index (row), it is giving us a data structure with a row for every word in the vocabulary. We want to make sure that stays as a single row with a column for every word. We can use `numpy's .reshape()` method. `.reshape(1, -1)` will do the trick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_tfidf = np.array(query_tfidf).reshape(1, -1)\n",
    "query_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a new variable and call it <tt>sim_to_first</tt>. We'll initially save this as a list, and we'll create it using a list comprehension that compares the tf-idf-weighted vector representation of the first speech to the vector for each speech in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_to_first = [cosine_similarity(query_tfidf, np.array(post).reshape(1,-1))[0][0] for idx, post in tfidf_df.iterrows()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've kept everything in the same order, but let's put our minds at ease by first confirming there are the same number of speeches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sim_to_first) == df.shape[0] == dtm.shape[0] == tfidf_df.shape[0] == new_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to be extra safe, let's make sure the first result--which should be comparing the first speech to itself--has a similarity of 1.0. There will always be some noise, but this is effectively 1.0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sim_to_first[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good! Now we can add the new variable to our original dataframe, which has useful metadata, namely the president who gave the speech and the year it was given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sim_to_first\"] = sim_to_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Using seaborn, pandas, or pyplot itself with missing data may mean missing datapoints are interpolated. We can see this if we explicitly interperolate a value for the missing year, 1933.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in range(1791,2019) if i not in df.year.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = copy.copy(df)\n",
    "tmp.loc[len(tmp.index)] = [\"Roosevelt2\", 1933, np.nan, \"Democrat\", np.nan, np.nan]\n",
    "tmp = tmp.sort_values(\"year\")\n",
    "tmp = tmp.reset_index()\n",
    "tmp.sim_to_first = tmp.sim_to_first.interpolate()\n",
    "\n",
    "tmp = tmp[tmp.year.isin(range(1930,1940))]\n",
    "display(tmp.head())\n",
    "\n",
    "sns.lineplot(x=\"year\", y=\"sim_to_first\", data=tmp[tmp.index != 0])\n",
    "plt.title(\"Similarity to 1791 State of the Union\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Cosine\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=\"year\", y=\"sim_to_first\", data=tmp[tmp.index != 0])\n",
    "plt.title(\"Similarity to 1791 State of the Union\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Cosine\")\n",
    "plt.ylim(0.0, 1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=\"year\", y=\"sim_to_first\", data=df[df.index != 0])\n",
    "plt.title(\"Similarity to 1791 State of the Union\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Cosine\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=\"year\", y=\"sim_to_first\", data=df[df.index != 0])\n",
    "plt.title(\"Similarity to 1791 State of the Union\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Cosine\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Similarity to a President\n",
    "Now let's try a less obvious starting point: the \"average\" speech for a particular president. I've put \"average\" in scare quotes because the idea of just averaging these representations may seem a little sketchy, but we are, in fact, going to average them. You can think of the average as the centroid (center) of the cluster of points belonging to a particular president's speeches in this vector space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.president==\"Polk\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "James K. Polk's speeches have the indices 54, 55, 56, and 57.\n",
    "\n",
    "We could have also used the following line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.president==\"Polk\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polk_tfidf = tfidf_df[tfidf_df.index.isin([54, 55, 56, 57])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polk_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll average them, and it's *really* important to keep checking the shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polk_average = polk_tfidf.mean()\n",
    "polk_average.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polk_average = np.array(polk_average).reshape(1, -1)\n",
    "polk_average.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll create a variable <tt>sim_to_polk</tt> in the same manner as the previous example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sim_to_polk\"] = [cosine_similarity(polk_average, np.array(post).reshape(1,-1))[0][0] for idx, post in tfidf_df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=\"year\", y=\"sim_to_polk\", data=df[df.president != \"Polk\"])\n",
    "plt.title(\"Similarity to James K. Polk's State of the Union Addresses\")\n",
    "plt.xlabel(\"Year\\n(Polk Administration in Orange)\")\n",
    "plt.ylabel(\"Cosine\")\n",
    "plt.axvspan(1845, 1848, alpha = 0.7, color = \"orange\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=\"year\", y=\"sim_to_polk\", data=df[df.president != \"Polk\"])\n",
    "plt.title(\"Similarity to James K. Polk's State of the Union Addresses\")\n",
    "plt.xlabel(\"Year\\n(Polk Administration in Orange)\")\n",
    "plt.ylabel(\"Cosine\")\n",
    "plt.axvspan(1845, 1848, alpha = 0.7, color = \"orange\")\n",
    "plt.ylim(0.0, 1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(\"sim_to_polk\", ascending=False) # most similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.president != \"Polk\"].sort_values(\"sim_to_polk\", ascending=False).head(10) # most similar, excluding Polk himself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: Similarity to the Whigs\n",
    "\n",
    "We also know the party of the president who gave the speech (although this variable may not be meaningful for the first several presidents). We can calculate the centroid for a party and then calculate the similarity of every subsequent speech to that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.party==\"Whig\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whig_indices = df[df.party==\"Whig\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whig_tfidf = tfidf_df[tfidf_df.index.isin(whig_indices)]\n",
    "whig_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whig_average = whig_tfidf.mean()\n",
    "whig_average.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whig_average = np.array(whig_average).reshape(1, -1)\n",
    "whig_average.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sim_to_whig\"] = [cosine_similarity(whig_average, np.array(post).reshape(1,-1))[0][0] for idx, post in tfidf_df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=\"year\", y=\"sim_to_whig\", data=df)\n",
    "plt.title(\"Similarity to Average Whig Address\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Cosine\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Exercise 1</b><br><br>\n",
    "    For this exercise, pick a year when you think the State of the Union Address may have referred to consequential events. (Hint: You may want to pick the year after, depending on when the events happened and the month the State of the Union was given that year.)<br><br>\n",
    "    1.1 What sociologically significant events, institutions, or processes might make this year distinctive?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Your text here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    1.2 Identify the index\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.year == PICK_A_YEAR].index # replace \"PICK_A_YEAR\" with a year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    1.3 Get the tf-idf-weighted vector from the dataframe <tt>tfidf_df</tt>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_year_vec = tfidf_df.loc[YOUR_INDEX] # replace \"YOUR_INDEX\" with the index from the previous step\n",
    "chosen_year_vec = np.array(chosen_year_vec).reshape(1,-1)\n",
    "chosen_year_vec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    1.4 Run the cell below to calculate the cosine similarity of each speech to the speech from your chosen year\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sim_to_chosen_year\"] = [cosine_similarity(chosen_year_vec, np.array(post).reshape(1,-1))[0][0] for idx, post in tfidf_df.iterrows()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    1.5 What trend do you expect in how similar other speeches are? For example, will earlier or later speeches be more or less similar? Are there other years when the State of the Union may have been much more or much less similar?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Your answer here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    1.6 Plot the trend as in Example 1 above\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    1.7 What do you notice about the trend? Does the plot reflect your expectations? What might explain any differences?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Your answer here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Exercise 2</b><br><br>\n",
    "    Now, as in Example 2, you will examine trends in the similarity of State of the Union addresses to the average for a particular president.<br><br>\n",
    "    2.1 Pick a president other than James K. Polk. What sociologically significant events happened during that president's administration?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Your answer here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    2.2 Get the index or indices of that president's speeches. Save them to the variable <tt>pres_indices</tt>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pres_indices = df[df.president==\"PRESIDENT\"].index # replace \"PRESIDENT\" with the name as it appears in the data\n",
    "df.loc[pres_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    2.3 Get the subset of tf-idf-weighted vectors corresponding to those indices and save the result as the dataframe <tt>pres_tfidf</tt>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pres_tfidf = tfidf_df[tfidf_df.index.isin(pres_indices)]\n",
    "pres_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    2.4 Now calculate the centroid (average) of the vectors and display the shape using the <tt>.shape</tt> method.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pres_average = pres_tfidf.mean()\n",
    "pres_average.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    2.5 Reshape the vector (as in the examples above) using the <tt>.reshape</tt> method. The first number (the number of rows) should be 1, and the second number should be the number of words in the vocabulary.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pres_average = np.array(pres_average).reshape(1, -1)\n",
    "pres_average.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    2.5 Now calculate the similarity of each speech to that average, just as we have done in the examples above. Store this in a variable with an informative name like <tt>sim_to_pres</tt>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    2.6 What trends do you expect in the similarity of other documents to this average?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Your answer here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    2.7 Plot the trend.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    2.8 Does the plot match your expectations? What might explain any differences?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Your answer here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Exercise 3</b><br><br>\n",
    "    Now pick another group of speeches that were given in years during which sociologically significant events occurred. For example, you could pick the years during which a particular event occurred (e.g., the Civil War) or when a political party (other than the Whigs) held the office of the president. You will calculate the centroid of the vectors representing these speeches and plot the trend in similarity of all of the speeches to it, just as in the previous exercise. <br><br>\n",
    "    3.1 What group of years are you choosing, and what makes that period of time interesting?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Your answer here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    3.2 What do you expect the plotted trends in similarity to look like? Why?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Your answer here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    3.3 Following the steps in the previous exercise, calculate the centroid of the appropriate vectors, calculate the similarity of each speech to the centroid, and save the results in a variable with an informative name like <tt>sim_to_civil_war</tt> (but with a name that matches the period or group you chose).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    3.4 Plot the trend.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    3.5 Does the plot match your expectations? What might explain any differences? If you've offered potential explanations for any differences you observe, how could they be tested?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Your answer here_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
