{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d71bb66",
   "metadata": {},
   "source": [
    "#### Sociology 128D: Mining Culture Through Text Data: Introduction to Social Data Science – Summer '22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5498a9e5",
   "metadata": {},
   "source": [
    "# Notebook 6: Online Text and Social Networks\n",
    "\n",
    "In Notebooks 3 and 5, we used [TF-IDF weighting](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) to represent documents as vectors that could be compared and plotted. In doing so, we were focusing on the similarity of the language used in the documents. Other research has used different approaches to creating this kind of representation of entire communities on Reddit (e.g., [Martin, 2017](https://aclanthology.org/W17-2904.pdf)), but we may not only want to consider the similarity of *content* when comparing online communities such as subreddits. Depending on the type of data we have, there may be other kinds of information worth considering.\n",
    "\n",
    "In one of the readings for this week, [Hessel et al. (2015)](https://arxiv.org/abs/1511.03371) leverage two very different types of similarity: text similarity and *user similarity*, or the similarity of two subreddits based on their overlapping users. In their introduction, they write, \"By explicitly comparing the differences between the user-based and language-based metrics, we can discover relationships that might not be captured by using only a single similarity metric. For example, we can ask 'what do vegans do when they aren’t talking about veganism?'\" This kind of approach can give us leverage on apparent relationships between seemingly unrelated factors like political identity and taste. As [DellaPosta, Shi, and Macy (2015)](https://www.journals.uchicago.edu/doi/full/10.1086/681254) write in their classic paper on 'lifestyle politics':\n",
    "\n",
    "> In short, the puzzle of lifestyle politics compounds the curious formation of cultural enclaves among seemingly unrelated preferences. Why should liberals and conservatives differ systematically on lifestyle dimensions that have no apparent substantive relevance to political ideology? What are the social mechanisms that could produce a world of “latte liberals” and “bird-hunting conservatives”? (p. 1475)\n",
    "\n",
    "DellaPosta, Shi, and Macy argue that political identity and taste are linked due to the paired forces of [homophily](https://en.wikipedia.org/wiki/Homophily) and social influence (see also [McPherson, Smith-Lovin, and Cook, 2001](https://www.jstor.org/stable/pdf/2678628.pdf)). In brief, people associate with similar others, and people influence and are influenced by the people with whom they associate. If people seek one another out because they have one trait or set of traits in common and then acquire other traits from one another, the various traits may become correlated within the larger population. Additionally, different ideas or behaviors can become incredibly important for signaling a shared identity or membership in a common group.\n",
    "\n",
    "In this notebook, we will take a look at a different corpus of Reddit data, and we will see how considering text similarity, user similarity, and the combination of user similarity with text *dissimilarity* can shed light on how identity and taste are linked. For this notebook, we will only need to import `pandas` to manage the data and `matplotlib.pyplot` and `seaborn` to help with visualizations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d191e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42549b4",
   "metadata": {},
   "source": [
    "The dataset is available via Canvas, but was [provided by](https://jmhessel.com/projects/latent_interest/latent_interest.html) Hessel et al. to replicate their work. (Dr. Hessel personally approved sharing the corpus via Canvas for this class.) I have uploaded the full dataset, which includes all of the text as well, but if you just want to follow along with the core of this notebook, you can save space and time by downloading the two files we read in below.\n",
    "\n",
    "The two files we will import as dataframes and then merge are based on the different similarity metrics used in the original paper, namely text similarity and user similarity. Each file has two columns for the names of subreddits and a column indicating the similarity of the pair of subreddits represented by each row. We will use the `read_csv` method from `pandas` with an important twist: we will set the `sep` argument to `\"\\t\"` (tabs) instead of the default (commas).\n",
    "\n",
    "Although we have focused on TF-IDF weighting and [cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity) so far, Hessel et al. measure text similarity in a different way. Specifically, they train a topic model using [latent Dirichlet allocation](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation) to identify latent themes within the content of the posts to various subreddits. They then compare subreddits based on the probability distributions of the resulting topics using [Jensen-Shannon divergence](https://en.wikipedia.org/wiki/Jensen%E2%80%93Shannon_divergence). We will cover topic modeling in Week 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a4a266",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/RedditDataRelease/textSims/500-out-all.graph\", sep=\"\\t\", names=[\"sub1\", \"sub2\", \"text_sim\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3ef4d0",
   "metadata": {},
   "source": [
    "What makes the work of Hessel et al. so interesting is their use of different types of similarity. To measure user similarity, they use the [Jaccard index](https://en.wikipedia.org/wiki/Jaccard_index). You can think of this as representing each subreddit as a vector of all *users* (or 'redditors') in the dataset, where each element is binary: 1 if the user participates in the subreddit, and 0 if they do not. The Jaccard index quantifies the amount of overlap between two subreddits.\n",
    "\n",
    "We read in the file with text similarity as `df` because we read it in first and will merge the user similarity file with it. We'll read the file with user similarity in as `userSims` because the authors use that name for the folder and it's clear enough, but we won't do anything with that file on its own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4da65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "userSims = pd.read_csv(\"data/RedditDataRelease/userSims/jaccardSims-sparse.txt\", sep=\"\\t\", names=[\"sub1\", \"sub2\", \"user_sim\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c87234",
   "metadata": {},
   "source": [
    "Below, we combine the two dataframes using the `merge` method. You can read more about it [here](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html). As you can see when we look at the head of the dataframe, each row has a pair of subreddits, the text similarity, and the user similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f63178",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(userSims, on=[\"sub1\", \"sub2\"], how=\"left\")\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e820f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3ae00e",
   "metadata": {},
   "source": [
    "Taking a look at the shape of the dataframe, we can see there are about 5.2 million rows. Where does this number come from? This is the number of undirected ties in a network of all subreddits in the dataset. We can get the number of subreddits by using built-in set operations, specifically the union of the two columns with names of subreddits. As Hessel et al. write, the corpus represents about 3200 subreddits. We can compute the number of all possible undirected ties in a network using (N(N-1))/2, where N is the number of nodes (or vertices) in the network, which in this case means unique subreddits. We can see that the number of rows in the dataframe is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326cbbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28722d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SUBS = len(set(df.sub1).union(df.sub2))\n",
    "print(NUM_SUBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d70fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(NUM_SUBS * (NUM_SUBS - 1))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6cea1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"text_sim\", \"user_sim\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8e7af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(column=\"text_sim\", bins=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5682149f",
   "metadata": {},
   "source": [
    "The function below implements the rescaling the authors describe for text similarities so that below-average similarities count against the subreddit-subreddit dyad in later calculations. We will calculate the mean (`mu`) for the text similarity column overall. We then set below-average text similarity scores to 0.0 and rescale positive similarity scores using the formula in the paper. The way the function is written is slightly redundant, but it is written this way to show the connection to equation 3 in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed9bc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_text_similarity(sim: float, mu: float) -> float:\n",
    "    \"\"\"\n",
    "    Rescale text-based similarity as in equation 3 in\n",
    "    https://arxiv.org/abs/1511.03371\n",
    "    \"\"\"\n",
    "    if sim < mu:\n",
    "        return 0.0\n",
    "    sim = (sim - mu)/(1 - mu)\n",
    "    return max(0.0, sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec4c966",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = df[\"text_sim\"].mean()\n",
    "print(mu)\n",
    "\n",
    "df[\"text_sim_rescaled\"] = df[\"text_sim\"].apply(lambda x: scale_text_similarity(x, mu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c09a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(\"text_sim\", data = df.sample(1000))\n",
    "sns.kdeplot(\"text_sim_rescaled\", data = df.sample(1000))\n",
    "plt.legend([\"Original\", \"Rescaled\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89220df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"text_sim\", \"text_sim_rescaled\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45bf462",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eefdeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(\"text_sim\", ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae7c3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(\"user_sim\", ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb546aed",
   "metadata": {},
   "source": [
    "Next, we will calculate the latent interest measure put forth in the paper in equation 5. We will do this by multiplying the user similarity score for each subreddit-subreddit dyad by 1 minus the rescaled text similarity. In effect, we are assigning more weight to subreddits that are dissimilar, based on the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46043778",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"latent_interest\"] = df.user_sim * (1 - df.text_sim_rescaled) # equation 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc943853",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"latent_interest\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db143b0",
   "metadata": {},
   "source": [
    "Let's take a look at the top results for the r/vegan subreddit based on these different measures. Here, we are selecting the subset of rows where either sub1 or sub2 is equal to \"vegan\" and then sorting the results according to the different measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb1f571",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.sub1==\"vegan\")|(df.sub2==\"vegan\")].sort_values(\"text_sim\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ca784a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.sub1==\"vegan\")|(df.sub2==\"vegan\")].sort_values(\"user_sim\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e65cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.sub1==\"vegan\")|(df.sub2==\"vegan\")].sort_values(\"latent_interest\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68385a03",
   "metadata": {},
   "source": [
    "Although patterns of consumption (such as diet) may be driven by factors such as moral beliefs or identity, a lot of research has focused on the centrality of political identity (e.g., [Boutyline and Vaisey (2017)](https://www.journals.uchicago.edu/doi/full/10.1086/691274)). We can use this latent interest detection approach to see what different political groups are up to on Reddit (or *were* up to during the period covered by the data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bb0664",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.sub1==\"Conservative\")|(df.sub2==\"Conservative\")].sort_values(\"latent_interest\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cdd22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.sub1==\"Liberal\")|(df.sub2==\"Liberal\")].sort_values(\"latent_interest\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bc6271",
   "metadata": {},
   "source": [
    "## Extensions\n",
    "\n",
    "If you want to take a look at the text for a specific subreddit, you can use code like the following two cells. If you want to read in all of the text and convert it to a dataframe, the subsequent code will do that for you. It may take a minute or two to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f54d0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vegan = []\n",
    "\n",
    "with open(\"data/RedditDataRelease/redditTextBalanced.txt\", \"r\") as reader:\n",
    "    for line in reader:\n",
    "        line = line.strip().split(\"\\t\")\n",
    "        if line[1] == \"vegan\":\n",
    "            vegan.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0aff3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(vegan, columns=[\"label\", \"subreddit\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7d6da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time textBalanced = pd.read_csv(\"data/RedditDataRelease/redditTextBalanced.txt\", sep=\"\\t\", names=[\"label\", \"subreddit\", \"text\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3955b2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "textBalanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f06c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "textBalanced.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
