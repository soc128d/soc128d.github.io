{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sociology 128D: Mining Culture Through Text Data: Introduction to Social Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 7: Web Scraping and APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web scraping is a big topic. There are a lot of reasons someone might want to scrape web content, but the reason applicable to this class is to get data that may be useful for answering questions about some social phenomena.\n",
    "\n",
    "People who provide web content are typically savvy to the existence of tools for web scraping. You can often find references to automated web scraping in a site's Terms of Use (or equivalent), which often prohibit automated scraping.\n",
    "\n",
    "I'll just make two points here. First, the desirability of the data on a site is probably positively correlated with how prohibitive it is to scrape it. Second, we should try to be clear about what we mean by \"web scraping.\"\n",
    "\n",
    "Regarding the second point, we are typically referring to accessing a website's content in a way that's mediated by a tool or set of tools that makes it qualitatively different from browsing the web normally. As we'll see in our first example using the `requests` library, this can be as simple as using a line of Python code to store a web search in memory, rather than rendering it directly in a browser. We can then view what we've scraped (e.g., rendered HTML), which wouldn't be much different from normal browsing. We could also save it, or save some feature or set of features we've extracted from it; and doing this a lot is typically where things become problematic.\n",
    "\n",
    "At the most basic level, repeatedly scraping a site (or some part of it) means making repeated requests of the site's servers. That can be a problem in itself. The first point above just adds to this: sites may also want to protect their data, and may make it available subject to terms that prohibit automated scraping. Content is also served in different ways. Static websites are much easier to scrape than dynamic ones, which require a different approach.\n",
    "\n",
    "One compromise many sites make is to offer an application programming interface (API). In this notebook, we're going to keep our focus on getting data that may be useful for answering social research questions. Toward that end, we'll explore scraping static web content with an eye toward getting Twitter user handles for members of the US senate, and we'll then use those handles to get tweets. Finally, we'll use an API to access data from Reddit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "For this notebook, you'll need to install `beautifulsoup4`, `psaw`, `nest_asyncio`, and `twint`.\n",
    "\n",
    "If you use Anaconda, you can install `beautifulsoup4` and `async_io` by running the following lines in the Anaconda interpreter:\n",
    "\n",
    "```\n",
    "conda install -c anaconda beautifulsoup4 \n",
    "conda install -c conda-forge nest-asyncio\n",
    "```\n",
    "\n",
    "Otherwise, you install them using pip. (Depending on your setup, you may need to use pip3 instead.)\n",
    "\n",
    "```\n",
    "pip3 install beautifulsoup4\n",
    "pip3 install nest_asyncio\n",
    "```\n",
    "\n",
    "Regardless, you will need to install `psaw` using pip:\n",
    "\n",
    "```\n",
    "pip3 install psaw\n",
    "```\n",
    "\n",
    "And you will need to install `twint` by executing the following commands from the command line (e.g., the Anaconda interpreter):\n",
    "\n",
    "```\n",
    "git clone --depth=1 https://github.com/twintproject/twint.git\n",
    "cd twint\n",
    "pip3 install . -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import twint\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.core.display import display, HTML\n",
    "from psaw import PushshiftAPI\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping with Requests and BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1. Rendering Search Results inside Jupyter\n",
    "\n",
    "At its most basic level, \"scraping the web\" is just using a computer to access web content in a different way. The next two cells show how we can use the `requests` library to store the results of a web search in memory (in a variable we'll call <tt>results</tt>), which we can then render inside the notebook.\n",
    "\n",
    "We'll use `requests.get()` to get the web content we want to examine. The [`requests` library](https://docs.python-requests.org/en/master/) enables us to make HTTP requests, even with authentication.\n",
    "\n",
    "Running the second cell may change the way the notebook is displayed. You can comment it out and run the cell again if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.google.com/search?q=weather+stanford\"\n",
    "results = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(HTML(results.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2. Scraping Quotes from a Scraping Sandbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a sense of how scraping static content works, we'll start with a sandbox designed for this purpose. https://toscrape.com/ offers a couple of environments, including a [fictional bookstore](https://books.toscrape.com/). Since this is a class on text analysis, we're going to take a look at [another page](https://quotes.toscrape.com/), which displays quotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://quotes.toscrape.com/\"\n",
    "quotes_page = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Response.json of <Response [200]>>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes_page.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to note is that we can interact with the result like it's a string. If you type \"quotes_page.\" (ending with a period) and press the `tab` key, Jupyter will list several attributes you can explore, like the status code and headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      "<head>\n",
      "\t<meta charset=\"UTF-8\">\n",
      "\t<title>Quotes to Scrape</title>\n",
      "    <link rel=\"stylesheet\" href=\"/static/bootstrap.min.css\">\n",
      "    <link rel=\"stylesheet\" href=\"/static/main.css\">\n",
      "</head>\n",
      "<body>\n",
      "    <div class=\"container\">\n",
      "        <div class=\"row header-box\">\n",
      "            <div class=\"col-md-8\">\n",
      "                <h1>\n",
      "                    <a href=\"/\" style=\"text-decoration: none\">Quotes to Scrape</a>\n",
      "                </h1>\n",
      "            </div>\n",
      "            <div class=\"col-md\n"
     ]
    }
   ],
   "source": [
    "print(quotes_page.text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes_page.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Server': 'nginx/1.17.7', 'Date': 'Thu, 22 Jul 2021 01:42:01 GMT', 'Content-Type': 'text/html; charset=utf-8', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Vary': 'Accept-Encoding', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains', 'Content-Encoding': 'gzip'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes_page.headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) to parse the text and find the content we are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(quotes_page.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      " <head>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <title>\n",
      "   Quotes to Scrape\n",
      "  </title>\n",
      "  <link href=\"/static/bootstrap.min.css\" rel=\"stylesheet\"/>\n",
      "  <link href=\"/static/main.css\" rel=\"stylesheet\"/>\n",
      " </head>\n",
      " <body>\n",
      "  <div class=\"container\">\n",
      "   <div class=\"row header-box\">\n",
      "    <div class=\"col-md-8\">\n",
      "     <h1>\n",
      "      <a href=\"/\" style=\"text-decoration: none\">\n",
      "       Quotes to Scrape\n",
      "      </a>\n",
      "     </h1>\n",
      "    </div>\n",
      "    <div class=\"col-md-4\">\n",
      "     <p>\n",
      "      <a href=\"/login\">\n",
      "   \n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify()[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now search the <tt>soup</tt> for all kinds of content. If you type \"soup.\" (ending with a period) in a Code cell and press the `tab` key, Jupyter will show different attributes or methods that are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h1>\n",
       "<a href=\"/\" style=\"text-decoration: none\">Quotes to Scrape</a>\n",
       "</h1>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>\n",
       "<a href=\"/login\">Login</a>\n",
       "</p>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"/\" style=\"text-decoration: none\">Quotes to Scrape</a>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"alert-info\" href=\"#s-lg-guide-main\" id=\"s-lg-public-skiplink\">Skip to main content</a>,\n",
       " <a class=\"title-header title-header-large\" href=\"https://library.ucsd.edu/\">The Library</a>,\n",
       " <a class=\"title-logo\" href=\"https://www.ucsd.edu/\">\n",
       " <img alt=\"UC San Diego\" src=\"https://library.ucsd.edu/assets/libapps/shared/logo-ucsd-header.png\"/>\n",
       " </a>,\n",
       " <a href=\"https://library.ucsd.edu/research-and-collections/index.html\">Research &amp; Collections</a>,\n",
       " <a href=\"https://library.ucsd.edu/borrow-and-request/index.html\">Borrow &amp; Request</a>]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(\"a\")[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we print one `div` section (a chunk of the HTML) that shows a single quote and the author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     <div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n",
      "      <span class=\"text\" itemprop=\"text\">\n",
      "       “The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”\n",
      "      </span>\n",
      "      <span>\n",
      "       by\n",
      "       <small class=\"author\" itemprop=\"author\">\n",
      "        Albert Einstein\n",
      "       </small>\n",
      "       <a href=\"/author/Albert-Einstein\">\n",
      "        (about)\n",
      "       </a>\n",
      "      </span>\n",
      "      <div class=\"tags\">\n",
      "       Tags:\n",
      "       <meta class=\"keywords\" content=\"change,deep-thoughts,thinking,world\" itemprop=\"keywords\"/>\n",
      "       <a class=\"tag\" href=\"/tag/change/page/1/\">\n",
      "        change\n",
      "       </a>\n",
      "       <a class=\"tag\" href=\"/tag/deep-thoughts/page/1/\">\n",
      "        deep-thoughts\n",
      "       </a>\n",
      "       <a class=\"tag\" href=\"/tag/thinking/page/1/\">\n",
      "        thinking\n",
      "       </a>\n",
      "       <a class=\"tag\" href=\"/tag/world/page/1/\">\n",
      "        world\n",
      "       </a>\n",
      "      </div>\n",
      "     </div>\n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify()[600:1538])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.find_all()` method can be used for various types of content. Here we use it to get all of the `div` tags containing quotes. We then use `.find_all()` on each result to find the `span` tags nested inside. We use Python's `str.replace()` method to get rid of some unwanted text and print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”\n",
      "by Albert Einstein\n",
      "\n",
      "\n",
      "“It is our choices, Harry, that show what we truly are, far more than our abilities.”\n",
      "by J.K. Rowling\n",
      "\n",
      "\n",
      "“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”\n",
      "by Albert Einstein\n",
      "\n",
      "\n",
      "“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”\n",
      "by Jane Austen\n",
      "\n",
      "\n",
      "“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\n",
      "by Marilyn Monroe\n",
      "\n",
      "\n",
      "“Try not to become a man of success. Rather become a man of value.”\n",
      "by Albert Einstein\n",
      "\n",
      "\n",
      "“It is better to be hated for what you are than to be loved for what you are not.”\n",
      "by André Gide\n",
      "\n",
      "\n",
      "“I have not failed. I've just found 10,000 ways that won't work.”\n",
      "by Thomas A. Edison\n",
      "\n",
      "\n",
      "“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\n",
      "by Eleanor Roosevelt\n",
      "\n",
      "\n",
      "“A day without sunshine is like, you know, night.”\n",
      "by Steve Martin\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for thing1 in soup.find_all(class_=\"quote\"):\n",
    "    for span in thing1.find_all(\"span\"):\n",
    "        print(span.text.replace(\"(about)\", \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3. Something Useful: Identifying Twitter Handles of Members of the Senate\n",
    "\n",
    "As we've noted, at its most basic level scraping is just accessing a site. Here we will scrape a \"real\" website--but we are only going to make *one* request. Specifically, we'll get the Twitter handles (along with state and party) of each current US senator from a site maintained by the UC San Diego Library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://ucsd.libguides.com/congress_twitter/senators\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "senate_page = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(senate_page.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(senate_page.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can compare the way the HTML is printed when using `.prettify()` on <tt>soup</tt> to printing the text from the original result from `requests`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you explore the site in a browser or just scroll through the <tt>soup</tt>, you can see that the names, states, parties, and Twitter handles of the senators are arranged in a table, which is convenient for us. We'll use `.find_all()` to identify the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(soup.find_all(\"table\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.Tag'> 3\n",
      "<class 'bs4.element.Tag'> 3\n"
     ]
    }
   ],
   "source": [
    "tables = soup.find_all(\"table\")\n",
    "for table in tables:\n",
    "    print(type(table), len(table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see that the info we want is inside `tr` tags, which are rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table class=\"table table-bordered table-striped table-hover table-condensed\" style=\"border: 1px solid rgb(221, 221, 221);\">\n",
      "<tbody>\n",
      "<tr>\n",
      "<td class=\"ck_border\" style=\"border: 1px solid rgb(221, 221, 221);\"><strong>Senator</strong></td>\n",
      "<td class=\"ck_border\" style=\"border: 1px solid rgb(221, 221, 221); text-align: center;\"><strong>State</strong></td>\n",
      "<td class=\"ck_border\" style=\"border: 1px solid rgb(221, 221, 221); text-align: center;\"><strong>Party</strong></td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"ck_border\" style=\"border: 1px solid rgb(221, 221, 221);\"><a href=\"https://twitter.com/SenatorBaldwin\">Baldwin, Tammy</a></td>\n",
      "<td class=\"ck_border\" style=\"border: 1px solid rgb(221, 221, 221); text-align: center;\">WI</td>\n",
      "<td class=\"ck_border\" style=\"border: 1px solid rgb(221, 221, 221); text-align: center;\">D</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"ck_border\" style=\"border: 1px solid rgb(221, 221, 221);\"><a href=\"https://twitter.com/SenJohnBarrasso\">Barrasso, John</a></td>\n",
      "<td class=\"ck_border\" style=\"border: 1px sol\n"
     ]
    }
   ],
   "source": [
    "print(str(tables[0])[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The information we want for each senator (name, handle, state, and party) is contained in one row. The handle is in the URL of the `a` tag, while the senator's name is in the text of that tag. The state and party are in additional `td` tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tr>\n",
       "<td class=\"ck_border\" style=\"border: 1px solid rgb(221, 221, 221);\"><a href=\"https://twitter.com/SenatorBaldwin\">Baldwin, Tammy</a></td>\n",
       "<td class=\"ck_border\" style=\"border: 1px solid rgb(221, 221, 221); text-align: center;\">WI</td>\n",
       "<td class=\"ck_border\" style=\"border: 1px solid rgb(221, 221, 221); text-align: center;\">D</td>\n",
       "</tr>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables[0].findAll(\"tr\")[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use `enumerate()` with a for loop just to look at the first few results.\n",
    "\n",
    "This code finds all of the `tr` tags, ignores any without a link (e.g., to a Twitter account), finds all of the elements of the `ck_border` class, and prints the text. This prints the senator's name, state, and party. The `a` tag's attributes are like a dictionary, and the value for the key \"href\" is the URL to the senator's Twitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baldwin, Tammy\n",
      "WI\n",
      "D\n",
      "https://twitter.com/SenatorBaldwin\n",
      "\n",
      "Barrasso, John\n",
      "WY\n",
      "R\n",
      "https://twitter.com/SenJohnBarrasso\n",
      "\n",
      "Bennet, Michael\n",
      "CO\n",
      "D\n",
      "https://twitter.com/SenatorBennet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, result in enumerate(soup.find_all(\"tr\")):\n",
    "    if i < 4:\n",
    "        if result.a:\n",
    "            for element in result.find_all(class_=\"ck_border\"):\n",
    "                print(element.text)\n",
    "            print(result.a.attrs[\"href\"])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have figured out the way the information is structured, we will extract the name, state, party, and Twitter handle for each US senator. We'll create an empty list called <tt>senator_data</tt> to store the data initially. We'll use a nested for loop just like the one above, for we'll append each senator's name, state, party, and handle to a list called <tt>row</tt> before appending that row--one per senator--to <tt>senator_data</tt>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tr>\n",
      "<td class=\"ck_border\" style=\"border: 1px solid rgb(221, 221, 221);\"><strong>Senator</strong></td>\n",
      "<td class=\"ck_border\" style=\"border: 1px solid rgb(221, 221, 221); text-align: center;\"><strong>State</strong></td>\n",
      "<td class=\"ck_border\" style=\"border: 1px solid rgb(221, 221, 221); text-align: center;\"><strong>Party</strong></td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"ck_border\" style=\"border: 1px solid rgb(221, 221, 221);\"><strong>Senator</strong></td>\n",
      "<td class=\"ck_border\" style=\"border: 1px solid rgb(221, 221, 221); text-align: center;\"><strong>State</strong></td>\n",
      "<td class=\"ck_border\" style=\"border: 1px solid rgb(221, 221, 221); text-align: center;\"><strong>Party</strong></td>\n",
      "</tr>\n"
     ]
    }
   ],
   "source": [
    "senator_data = []\n",
    "\n",
    "for result in soup.find_all(\"tr\"):\n",
    "    if result.a:\n",
    "        row = []\n",
    "        for element in result.find_all(class_=\"ck_border\"):\n",
    "            row.append(element.text)\n",
    "        handle = result.a.attrs[\"href\"]\n",
    "        handle = handle.replace(\"https://twitter.com/\", \"\")\n",
    "        row.append(handle)\n",
    "        senator_data.append(row)\n",
    "    else:\n",
    "        print(result) # show the rows that aren't added to the dataset we're making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Baldwin, Tammy', 'WI', 'D', 'SenatorBaldwin'],\n",
       " ['Barrasso, John', 'WY', 'R', 'SenJohnBarrasso'],\n",
       " ['Bennet, Michael', 'CO', 'D', 'SenatorBennet'],\n",
       " ['Blackburn, Marsha', 'TN', 'R', 'MarshaBlackburn'],\n",
       " ['Blumenthal, Richard', 'CT', 'D', 'SenBlumenthal']]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senator_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(senator_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create a pandas dataframe from this list of lists. The `columns` argument lets us name the columns in the resulting dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(senator_data, columns=[\"senator\", \"state\", \"party\", \"twitter_handle\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 4)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>senator</th>\n",
       "      <th>state</th>\n",
       "      <th>party</th>\n",
       "      <th>twitter_handle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baldwin, Tammy</td>\n",
       "      <td>WI</td>\n",
       "      <td>D</td>\n",
       "      <td>SenatorBaldwin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barrasso, John</td>\n",
       "      <td>WY</td>\n",
       "      <td>R</td>\n",
       "      <td>SenJohnBarrasso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bennet, Michael</td>\n",
       "      <td>CO</td>\n",
       "      <td>D</td>\n",
       "      <td>SenatorBennet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Blackburn, Marsha</td>\n",
       "      <td>TN</td>\n",
       "      <td>R</td>\n",
       "      <td>MarshaBlackburn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Blumenthal, Richard</td>\n",
       "      <td>CT</td>\n",
       "      <td>D</td>\n",
       "      <td>SenBlumenthal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               senator state party   twitter_handle\n",
       "0       Baldwin, Tammy    WI     D   SenatorBaldwin\n",
       "1       Barrasso, John    WY     R  SenJohnBarrasso\n",
       "2      Bennet, Michael    CO     D    SenatorBennet\n",
       "3    Blackburn, Marsha    TN     R  MarshaBlackburn\n",
       "4  Blumenthal, Richard    CT     D    SenBlumenthal"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>senator</th>\n",
       "      <th>state</th>\n",
       "      <th>party</th>\n",
       "      <th>twitter_handle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Warren, Elizabeth</td>\n",
       "      <td>MA</td>\n",
       "      <td>D</td>\n",
       "      <td>SenWarren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Whitehouse, Sheldon</td>\n",
       "      <td>RI</td>\n",
       "      <td>D</td>\n",
       "      <td>SenWhitehouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Wicker, Roger</td>\n",
       "      <td>MS</td>\n",
       "      <td>R</td>\n",
       "      <td>SenatorWicker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Wyden, Ron</td>\n",
       "      <td>OR</td>\n",
       "      <td>D</td>\n",
       "      <td>RonWyden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Young, Todd</td>\n",
       "      <td>IN</td>\n",
       "      <td>R</td>\n",
       "      <td>SenToddYoung</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                senator state party twitter_handle\n",
       "95    Warren, Elizabeth    MA     D      SenWarren\n",
       "96  Whitehouse, Sheldon    RI     D  SenWhitehouse\n",
       "97        Wicker, Roger    MS     R  SenatorWicker\n",
       "98           Wyden, Ron    OR     D       RonWyden\n",
       "99          Young, Todd    IN     R   SenToddYoung"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"senate_twitter_dataframe.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Tweets using `twint`\n",
    "\n",
    "[`twint`](https://github.com/twintproject/twint) describes itself as \"an advanced Twitter scraping tool written in Python that allows for scraping Tweets from Twitter profiles without using Twitter's API.\" `twint` has been featured in plenty of guides to scraping tweets, but there seem to be issues such as the way it handles dates, among other problems. One workaround is to [handle some of the configuration in the search string itself](https://stackoverflow.com/a/66731272) using Twitter's search operators, rather than configuring `twint` as intended.\n",
    "\n",
    "You can see Twitter's standard search operators [here](https://developer.twitter.com/en/docs/twitter-api/v1/rules-and-filtering/search-operators).\n",
    "\n",
    "[Here are some helpful thoughts](https://thoughtfaucet.com/search-twitter-by-location/) about using (and the limitations of) location data, including [tips for finding geocodes](https://thoughtfaucet.com/search-twitter-by-location/make-a-geocode-for-twitter-location-search/) and some examples of searching for tweets from [particular events](https://thoughtfaucet.com/search-twitter-by-location/examples/).\n",
    "\n",
    "**Note:** I recommend [applying for a Twitter developer account](https://developer.twitter.com/en/apply-for-access) and accessing tweets through the official API. We will use `twint` for this example, but I do not recommend violating Twitter's terms by accessing excessive amounts of data (etc.). I've set the tweet limits low for this notebook for a reason.\n",
    "\n",
    "First, we'll look at tweets from US senators around April 28, when President Biden [addressed a joint session of Congress](https://en.wikipedia.org/wiki/2021_Joe_Biden_speech_to_a_joint_session_of_Congress). Next, we'll look at geotagged tweets.\n",
    "\n",
    "\n",
    "\n",
    "### Example 1. Tweets from US Senators\n",
    "\n",
    "We'll use the dataframe we created in the previous section to identify the twitter handles of current US senators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"senate_twitter_dataframe.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = twint.Config()\n",
    "c.Hide_output = True\n",
    "c.Store_csv = True\n",
    "c.Output = \"senate_tweets.csv\"\n",
    "c.Limit = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_twint = input(\"Scrape twitter data? \")\n",
    "\n",
    "if run_twint in [\"yes\", \"y\"]:\n",
    "    for handle in df.twitter_handle.values:\n",
    "        searchstr = f\"from:{handle} until:2021-04-29 since:2021-04-28\"\n",
    "        c.Search = searchstr\n",
    "        twint.run.Search(c)\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = pd.read_csv(\"senate_tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2021-04-27', '2021-04-28', (379, 36))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.date.min(), tweets_df.date.max(), tweets_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>timezone</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "      <th>place</th>\n",
       "      <th>...</th>\n",
       "      <th>geo</th>\n",
       "      <th>source</th>\n",
       "      <th>user_rt_id</th>\n",
       "      <th>user_rt</th>\n",
       "      <th>retweet_id</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>retweet_date</th>\n",
       "      <th>translate</th>\n",
       "      <th>trans_src</th>\n",
       "      <th>trans_dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1387480099763757056</td>\n",
       "      <td>1387480099763757056</td>\n",
       "      <td>2021-04-28 11:53:28 Pacific Daylight Time</td>\n",
       "      <td>2021-04-28</td>\n",
       "      <td>11:53:28</td>\n",
       "      <td>-700</td>\n",
       "      <td>1074518754</td>\n",
       "      <td>senatorbaldwin</td>\n",
       "      <td>Sen. Tammy Baldwin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1387458980025446406</td>\n",
       "      <td>1387458980025446406</td>\n",
       "      <td>2021-04-28 10:29:33 Pacific Daylight Time</td>\n",
       "      <td>2021-04-28</td>\n",
       "      <td>10:29:33</td>\n",
       "      <td>-700</td>\n",
       "      <td>1074518754</td>\n",
       "      <td>senatorbaldwin</td>\n",
       "      <td>Sen. Tammy Baldwin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1387443098502975490</td>\n",
       "      <td>1387443098502975490</td>\n",
       "      <td>2021-04-28 09:26:26 Pacific Daylight Time</td>\n",
       "      <td>2021-04-28</td>\n",
       "      <td>09:26:26</td>\n",
       "      <td>-700</td>\n",
       "      <td>1074518754</td>\n",
       "      <td>senatorbaldwin</td>\n",
       "      <td>Sen. Tammy Baldwin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1387524261951295490</td>\n",
       "      <td>1387524261951295490</td>\n",
       "      <td>2021-04-28 14:48:57 Pacific Daylight Time</td>\n",
       "      <td>2021-04-28</td>\n",
       "      <td>14:48:57</td>\n",
       "      <td>-700</td>\n",
       "      <td>202206694</td>\n",
       "      <td>senjohnbarrasso</td>\n",
       "      <td>Sen. John Barrasso</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1387508940645228546</td>\n",
       "      <td>1387508940645228546</td>\n",
       "      <td>2021-04-28 13:48:04 Pacific Daylight Time</td>\n",
       "      <td>2021-04-28</td>\n",
       "      <td>13:48:04</td>\n",
       "      <td>-700</td>\n",
       "      <td>202206694</td>\n",
       "      <td>senjohnbarrasso</td>\n",
       "      <td>Sen. John Barrasso</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id      conversation_id  \\\n",
       "0  1387480099763757056  1387480099763757056   \n",
       "1  1387458980025446406  1387458980025446406   \n",
       "2  1387443098502975490  1387443098502975490   \n",
       "3  1387524261951295490  1387524261951295490   \n",
       "4  1387508940645228546  1387508940645228546   \n",
       "\n",
       "                                  created_at        date      time  timezone  \\\n",
       "0  2021-04-28 11:53:28 Pacific Daylight Time  2021-04-28  11:53:28      -700   \n",
       "1  2021-04-28 10:29:33 Pacific Daylight Time  2021-04-28  10:29:33      -700   \n",
       "2  2021-04-28 09:26:26 Pacific Daylight Time  2021-04-28  09:26:26      -700   \n",
       "3  2021-04-28 14:48:57 Pacific Daylight Time  2021-04-28  14:48:57      -700   \n",
       "4  2021-04-28 13:48:04 Pacific Daylight Time  2021-04-28  13:48:04      -700   \n",
       "\n",
       "      user_id         username                name  place  ... geo source  \\\n",
       "0  1074518754   senatorbaldwin  Sen. Tammy Baldwin    NaN  ... NaN    NaN   \n",
       "1  1074518754   senatorbaldwin  Sen. Tammy Baldwin    NaN  ... NaN    NaN   \n",
       "2  1074518754   senatorbaldwin  Sen. Tammy Baldwin    NaN  ... NaN    NaN   \n",
       "3   202206694  senjohnbarrasso  Sen. John Barrasso    NaN  ... NaN    NaN   \n",
       "4   202206694  senjohnbarrasso  Sen. John Barrasso    NaN  ... NaN    NaN   \n",
       "\n",
       "  user_rt_id user_rt retweet_id  reply_to  retweet_date  translate trans_src  \\\n",
       "0        NaN     NaN        NaN        []           NaN        NaN       NaN   \n",
       "1        NaN     NaN        NaN        []           NaN        NaN       NaN   \n",
       "2        NaN     NaN        NaN        []           NaN        NaN       NaN   \n",
       "3        NaN     NaN        NaN        []           NaN        NaN       NaN   \n",
       "4        NaN     NaN        NaN        []           NaN        NaN       NaN   \n",
       "\n",
       "  trans_dest  \n",
       "0        NaN  \n",
       "1        NaN  \n",
       "2        NaN  \n",
       "3        NaN  \n",
       "4        NaN  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "      <th>tweet</th>\n",
       "      <th>likes_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>senjackyrosen</td>\n",
       "      <td>Senator Jacky Rosen</td>\n",
       "      <td>We have to expand broadband access in communit...</td>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>senatorbraun</td>\n",
       "      <td>Senator Mike Braun</td>\n",
       "      <td>\"Sen. Braun has proposed legislation to elimin...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>senjohnkennedy</td>\n",
       "      <td>John Kennedy</td>\n",
       "      <td>What I expect Pres. Biden to say tonight:  1. ...</td>\n",
       "      <td>695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>sencapito</td>\n",
       "      <td>Shelley Moore Capito</td>\n",
       "      <td>Students shouldn’t have to worry about whether...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>sensherrodbrown</td>\n",
       "      <td>Sherrod Brown</td>\n",
       "      <td>This is what paying workers a living wage look...</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>senatordurbin</td>\n",
       "      <td>Senator Dick Durbin</td>\n",
       "      <td>Each of my guests has firsthand experience of ...</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>sentedcruz</td>\n",
       "      <td>Senator Ted Cruz</td>\n",
       "      <td>This is a crisis.  #BidenBorderCrisis</td>\n",
       "      <td>1712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>senjeffmerkley</td>\n",
       "      <td>Senator Jeff Merkley</td>\n",
       "      <td>Excited to watch @POTUS’s joint address with N...</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>senfeinstein</td>\n",
       "      <td>Senator Dianne Feinstein</td>\n",
       "      <td>Reports that the Biden administration will ban...</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>senbobcasey</td>\n",
       "      <td>Senator Bob Casey</td>\n",
       "      <td>There are some powerful &amp;amp; wealthy people i...</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            username                      name  \\\n",
       "281    senjackyrosen       Senator Jacky Rosen   \n",
       "33      senatorbraun        Senator Mike Braun   \n",
       "177   senjohnkennedy              John Kennedy   \n",
       "44         sencapito      Shelley Moore Capito   \n",
       "37   sensherrodbrown             Sherrod Brown   \n",
       "108    senatordurbin       Senator Dick Durbin   \n",
       "86        sentedcruz          Senator Ted Cruz   \n",
       "228   senjeffmerkley      Senator Jeff Merkley   \n",
       "123     senfeinstein  Senator Dianne Feinstein   \n",
       "55       senbobcasey         Senator Bob Casey   \n",
       "\n",
       "                                                 tweet  likes_count  \n",
       "281  We have to expand broadband access in communit...          421  \n",
       "33   \"Sen. Braun has proposed legislation to elimin...            8  \n",
       "177  What I expect Pres. Biden to say tonight:  1. ...          695  \n",
       "44   Students shouldn’t have to worry about whether...           15  \n",
       "37   This is what paying workers a living wage look...          201  \n",
       "108  Each of my guests has firsthand experience of ...          130  \n",
       "86               This is a crisis.  #BidenBorderCrisis         1712  \n",
       "228  Excited to watch @POTUS’s joint address with N...          142  \n",
       "123  Reports that the Biden administration will ban...          144  \n",
       "55   There are some powerful &amp; wealthy people i...          179  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df[[\"username\", \"name\", \"tweet\", \"likes_count\"]].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2. Geocoded Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To take a break from politics, we'll look at tweets sent from near Deer District in Milwaukee on July 20 as up to 65,000 fans celebrated the Bucks' NBA title. The `geocode` argument in <tt>searchstr</tt> includes the longitude, latitude, and radius. This time, we aren't specifying a username/handle, and we aren't including an actual search term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = twint.Config()\n",
    "c.Hide_output = True\n",
    "c.Store_csv = True\n",
    "c.Output = \"geo_tweets.csv\"\n",
    "c.Limit = 1000\n",
    "searchstr = \"until:2021-07-21 since:2021-07-19 geocode:43.045110,-87.915820,5km\" # within 5km of Deer District\n",
    "c.Search = searchstr\n",
    "twint.run.Search(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df = pd.read_csv(\"geo_tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2021-07-20', '2021-07-20', (1000, 36))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_df.date.min(), geo_df.date.max(), geo_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>timezone</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "      <th>place</th>\n",
       "      <th>...</th>\n",
       "      <th>geo</th>\n",
       "      <th>source</th>\n",
       "      <th>user_rt_id</th>\n",
       "      <th>user_rt</th>\n",
       "      <th>retweet_id</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>retweet_date</th>\n",
       "      <th>translate</th>\n",
       "      <th>trans_src</th>\n",
       "      <th>trans_dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1417635421417267203</td>\n",
       "      <td>1417522585936568323</td>\n",
       "      <td>2021-07-20 16:59:57 Pacific Daylight Time</td>\n",
       "      <td>2021-07-20</td>\n",
       "      <td>16:59:57</td>\n",
       "      <td>-700</td>\n",
       "      <td>856597620306968576</td>\n",
       "      <td>tweetiestate</td>\n",
       "      <td>tweetiestate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1417635401251053573</td>\n",
       "      <td>1417635401251053573</td>\n",
       "      <td>2021-07-20 16:59:52 Pacific Daylight Time</td>\n",
       "      <td>2021-07-20</td>\n",
       "      <td>16:59:52</td>\n",
       "      <td>-700</td>\n",
       "      <td>998242960646049797</td>\n",
       "      <td>foxconnaerials</td>\n",
       "      <td>Foxconn Aerials</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1417635400454184962</td>\n",
       "      <td>1417635400454184962</td>\n",
       "      <td>2021-07-20 16:59:52 Pacific Daylight Time</td>\n",
       "      <td>2021-07-20</td>\n",
       "      <td>16:59:52</td>\n",
       "      <td>-700</td>\n",
       "      <td>146943128</td>\n",
       "      <td>danmolloytv</td>\n",
       "      <td>Dan Molloy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1417635389548941312</td>\n",
       "      <td>1417635389548941312</td>\n",
       "      <td>2021-07-20 16:59:49 Pacific Daylight Time</td>\n",
       "      <td>2021-07-20</td>\n",
       "      <td>16:59:49</td>\n",
       "      <td>-700</td>\n",
       "      <td>705336188</td>\n",
       "      <td>tinker_pix</td>\n",
       "      <td>FlutterBy 🦋</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1417635385665011714</td>\n",
       "      <td>1417635385665011714</td>\n",
       "      <td>2021-07-20 16:59:48 Pacific Daylight Time</td>\n",
       "      <td>2021-07-20</td>\n",
       "      <td>16:59:48</td>\n",
       "      <td>-700</td>\n",
       "      <td>368905822</td>\n",
       "      <td>njanczak7</td>\n",
       "      <td>nate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id      conversation_id  \\\n",
       "0  1417635421417267203  1417522585936568323   \n",
       "1  1417635401251053573  1417635401251053573   \n",
       "2  1417635400454184962  1417635400454184962   \n",
       "3  1417635389548941312  1417635389548941312   \n",
       "4  1417635385665011714  1417635385665011714   \n",
       "\n",
       "                                  created_at        date      time  timezone  \\\n",
       "0  2021-07-20 16:59:57 Pacific Daylight Time  2021-07-20  16:59:57      -700   \n",
       "1  2021-07-20 16:59:52 Pacific Daylight Time  2021-07-20  16:59:52      -700   \n",
       "2  2021-07-20 16:59:52 Pacific Daylight Time  2021-07-20  16:59:52      -700   \n",
       "3  2021-07-20 16:59:49 Pacific Daylight Time  2021-07-20  16:59:49      -700   \n",
       "4  2021-07-20 16:59:48 Pacific Daylight Time  2021-07-20  16:59:48      -700   \n",
       "\n",
       "              user_id        username             name place  ... geo source  \\\n",
       "0  856597620306968576    tweetiestate     tweetiestate   NaN  ... NaN    NaN   \n",
       "1  998242960646049797  foxconnaerials  Foxconn Aerials   NaN  ... NaN    NaN   \n",
       "2           146943128     danmolloytv       Dan Molloy   NaN  ... NaN    NaN   \n",
       "3           705336188      tinker_pix      FlutterBy 🦋   NaN  ... NaN    NaN   \n",
       "4           368905822       njanczak7             nate   NaN  ... NaN    NaN   \n",
       "\n",
       "  user_rt_id user_rt retweet_id  reply_to  retweet_date  translate trans_src  \\\n",
       "0        NaN     NaN        NaN        []           NaN        NaN       NaN   \n",
       "1        NaN     NaN        NaN        []           NaN        NaN       NaN   \n",
       "2        NaN     NaN        NaN        []           NaN        NaN       NaN   \n",
       "3        NaN     NaN        NaN        []           NaN        NaN       NaN   \n",
       "4        NaN     NaN        NaN        []           NaN        NaN       NaN   \n",
       "\n",
       "  trans_dest  \n",
       "0        NaN  \n",
       "1        NaN  \n",
       "2        NaN  \n",
       "3        NaN  \n",
       "4        NaN  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>tweet</th>\n",
       "      <th>likes_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>mrmillymike</td>\n",
       "      <td>@DrKarateChop So you know you're on the right ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>jasonfechner</td>\n",
       "      <td>#Bucks in…  https://t.co/AbZmvtoOIB</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>jsarles414</td>\n",
       "      <td>BUCKS IN SIX FOR THE CULTURE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>ctown3721</td>\n",
       "      <td>There are children out in these streets.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>spectrumnews1wi</td>\n",
       "      <td>Traffic coming into the city is INSANE! #Game6...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>goddessblair8</td>\n",
       "      <td>My old subs are being disappointing and poor. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>chefgleon1</td>\n",
       "      <td>Just had the pleasure of finally meeting State...</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>bebravent</td>\n",
       "      <td>Director of Sales - Menomonee Falls, WI  https...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>mvlii89</td>\n",
       "      <td>@TALLY4K  https://t.co/AQbRRvA3bs</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>jeffbricco</td>\n",
       "      <td>@jimmyfk Over 90 minutes before game time. Pac...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            username                                              tweet  \\\n",
       "235      mrmillymike  @DrKarateChop So you know you're on the right ...   \n",
       "443     jasonfechner                #Bucks in…  https://t.co/AbZmvtoOIB   \n",
       "902       jsarles414                       BUCKS IN SIX FOR THE CULTURE   \n",
       "847        ctown3721           There are children out in these streets.   \n",
       "976  spectrumnews1wi  Traffic coming into the city is INSANE! #Game6...   \n",
       "436    goddessblair8  My old subs are being disappointing and poor. ...   \n",
       "578       chefgleon1  Just had the pleasure of finally meeting State...   \n",
       "390        bebravent  Director of Sales - Menomonee Falls, WI  https...   \n",
       "927          mvlii89                  @TALLY4K  https://t.co/AQbRRvA3bs   \n",
       "185       jeffbricco  @jimmyfk Over 90 minutes before game time. Pac...   \n",
       "\n",
       "     likes_count  \n",
       "235            1  \n",
       "443            1  \n",
       "902            0  \n",
       "847            1  \n",
       "976            3  \n",
       "436            1  \n",
       "578           72  \n",
       "390            0  \n",
       "927            0  \n",
       "185            3  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_df[[\"username\", \"tweet\", \"likes_count\"]].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Reddit Content using `psaw`\n",
    "\n",
    "Another amazing resource for social media data is [pushshift.io](https://pushshift.io/), which archives vast amounts of data and makes it easily accessible. We'll use the [`psaw` library](https://github.com/dmarx/psaw) to access content from the pushshift.io Reddit API.\n",
    "\n",
    "For this example, we'll get posts to r/WallStreetBets from the last week of January, 2021. During this time, there was a lot of excitement about the rise of the GameStop stock--and then trading was halted on some platforms, [such as Robinhood](https://www.reuters.com/business/us-congress-hold-hearings-gamestop-trading-state-stock-markets-2021-01-28/).\n",
    "\n",
    "First, create an instance of the `PushShiftAPI()` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = PushshiftAPI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the helper function <tt>get_results()</tt> to turn the results we get into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(subreddit: str, start_epoch, before_epoch, limit=10):\n",
    "    res = list(api.search_submissions(after=start_epoch,\n",
    "                                      before=before_epoch,\n",
    "                                      subreddit=subreddit,\n",
    "                                      limit=limit))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsb = []\n",
    "\n",
    "year = 2020\n",
    "month = 1\n",
    "days = range(24,31)\n",
    "\n",
    "epochs = []\n",
    "\n",
    "for day in days:\n",
    "    start_epoch=int(dt.datetime(year, month, day).timestamp())\n",
    "    try:\n",
    "        before_epoch=int(dt.datetime(year, month, day+1).timestamp())\n",
    "    except:\n",
    "        before_epoch=int(dt.datetime(year, month+1, 1).timestamp()) # first day of next month\n",
    "        \n",
    "    epochs.append((start_epoch, before_epoch))\n",
    "    res = get_results(\"WallStreetBets\", start_epoch, before_epoch)\n",
    "    wsb.append(res)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsb_flat = [post for sublist in wsb for post in sublist] # turn list of lists into list of posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsb_df = pd.DataFrame([post.d_ for post in wsb_flat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_awardings</th>\n",
       "      <th>allow_live_comments</th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>author_flair_richtext</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>author_flair_type</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>author_patreon_flair</th>\n",
       "      <th>author_premium</th>\n",
       "      <th>...</th>\n",
       "      <th>removed_by_category</th>\n",
       "      <th>media_metadata</th>\n",
       "      <th>thumbnail_height</th>\n",
       "      <th>thumbnail_width</th>\n",
       "      <th>post_hint</th>\n",
       "      <th>preview</th>\n",
       "      <th>media</th>\n",
       "      <th>media_embed</th>\n",
       "      <th>secure_media</th>\n",
       "      <th>secure_media_embed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>praisomnisf</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_3g6gzsv5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>WarmingSpiritualism</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_cfv4pgt</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>perfectentry1</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_ngkjp0s</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>RLaG69</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_318efk89</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>cheeseburger-</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_15wnnhpe</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  all_awardings  allow_live_comments               author  \\\n",
       "0            []                False          praisomnisf   \n",
       "1            []                False  WarmingSpiritualism   \n",
       "2            []                False        perfectentry1   \n",
       "3            []                False               RLaG69   \n",
       "4            []                False        cheeseburger-   \n",
       "\n",
       "  author_flair_css_class author_flair_richtext author_flair_text  \\\n",
       "0                   None                    []              None   \n",
       "1                   None                    []              None   \n",
       "2                   None                    []              None   \n",
       "3                   None                    []              None   \n",
       "4                   None                    []              None   \n",
       "\n",
       "  author_flair_type author_fullname  author_patreon_flair  author_premium  \\\n",
       "0              text     t2_3g6gzsv5                 False           False   \n",
       "1              text      t2_cfv4pgt                 False           False   \n",
       "2              text      t2_ngkjp0s                 False           False   \n",
       "3              text     t2_318efk89                 False            True   \n",
       "4              text     t2_15wnnhpe                 False           False   \n",
       "\n",
       "   ... removed_by_category  media_metadata  thumbnail_height  thumbnail_width  \\\n",
       "0  ...                 NaN             NaN               NaN              NaN   \n",
       "1  ...                 NaN             NaN               NaN              NaN   \n",
       "2  ...                 NaN             NaN               NaN              NaN   \n",
       "3  ...                 NaN             NaN               NaN              NaN   \n",
       "4  ...                 NaN             NaN               NaN              NaN   \n",
       "\n",
       "  post_hint preview media media_embed  secure_media  secure_media_embed  \n",
       "0       NaN     NaN   NaN         NaN           NaN                 NaN  \n",
       "1       NaN     NaN   NaN         NaN           NaN                 NaN  \n",
       "2       NaN     NaN   NaN         NaN           NaN                 NaN  \n",
       "3       NaN     NaN   NaN         NaN           NaN                 NaN  \n",
       "4       NaN     NaN   NaN         NaN           NaN                 NaN  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wsb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 70)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wsb_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>praisomnisf</td>\n",
       "      <td>The mainstream media is failing me, who do you...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WarmingSpiritualism</td>\n",
       "      <td>Priced In</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>perfectentry1</td>\n",
       "      <td>Ebay Earnings After the Bell Tuesday</td>\n",
       "      <td>It's pretty difficult to find a major brand na...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RLaG69</td>\n",
       "      <td>Follow the government pump and dump</td>\n",
       "      <td>Does anyone know where those fuckers in upper ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cheeseburger-</td>\n",
       "      <td>Is Bloomberg always so doom and gloom?</td>\n",
       "      <td>It seems to me if you purchase a Bloomberg ter...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>praisomnisf</td>\n",
       "      <td>Bears versus Bulls</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Noahnovanoah</td>\n",
       "      <td>Oh what I beautiful ride it has been.</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>wsb_itch</td>\n",
       "      <td>How to get away with insider trading</td>\n",
       "      <td>Hear me out, first you get insider information...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Noahnovanoah</td>\n",
       "      <td>Oh what a beautiful ride it has been.</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>LVXSIT</td>\n",
       "      <td>JPow Networth? I'd eat his ass too</td>\n",
       "      <td>Would this man really tank the economy? Get a ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 author                                              title  \\\n",
       "0           praisomnisf  The mainstream media is failing me, who do you...   \n",
       "1   WarmingSpiritualism                                          Priced In   \n",
       "2         perfectentry1               Ebay Earnings After the Bell Tuesday   \n",
       "3                RLaG69                Follow the government pump and dump   \n",
       "4         cheeseburger-             Is Bloomberg always so doom and gloom?   \n",
       "..                  ...                                                ...   \n",
       "65          praisomnisf                                 Bears versus Bulls   \n",
       "66         Noahnovanoah              Oh what I beautiful ride it has been.   \n",
       "67             wsb_itch               How to get away with insider trading   \n",
       "68         Noahnovanoah              Oh what a beautiful ride it has been.   \n",
       "69               LVXSIT                 JPow Networth? I'd eat his ass too   \n",
       "\n",
       "                                             selftext  score  \n",
       "0                                                          1  \n",
       "1                                                          1  \n",
       "2   It's pretty difficult to find a major brand na...      1  \n",
       "3   Does anyone know where those fuckers in upper ...      1  \n",
       "4   It seems to me if you purchase a Bloomberg ter...      1  \n",
       "..                                                ...    ...  \n",
       "65                                          [removed]      1  \n",
       "66                                                         1  \n",
       "67  Hear me out, first you get insider information...      1  \n",
       "68                                                         1  \n",
       "69  Would this man really tank the economy? Get a ...      1  \n",
       "\n",
       "[70 rows x 4 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wsb_df[[\"author\", \"title\", \"selftext\", \"score\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
