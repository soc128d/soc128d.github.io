{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sociology 128D: Mining Culture Through Text Data: Introduction to Social Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 3: Stylometry\n",
    "\n",
    "In this notebook, we're going to take our first step toward vector semantics, which is one of the main approaches we'll use in this class and which has had an enormous influence in cultural sociology! Specifically, we are going to build on Notebook 2 by using word and document frequencies to visualize how similar or dissimilar documents are.\n",
    "\n",
    "Please download the [State of the Union Corpus (1790-2018)](https://www.kaggle.com/rtatman/state-of-the-union-corpus-1989-2017), which was posted to Kaggle by Rachael Tatman and Liling Tan. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import Counter\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "sns.set_theme(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(os.listdir(\"sotu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_paths = [os.path.join(\"sotu\", f) for f in os.listdir(\"sotu\") if f.endswith(\".txt\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(open(address_paths[0], \"r\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_sotu_name_year_text(f: str):\n",
    "    \"\"\"Return the name, year, and text of a SOTU.\"\"\"\n",
    "    doc = open(f, \"r\").read().strip()\n",
    "    f = os.path.split(f)[-1] # this \n",
    "    f = f.replace(\".txt\", \"\")\n",
    "    pres, year = f.split(\"_\")\n",
    "    return pres, year, doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_sotu_name_year_text(address_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "presidents = []\n",
    "years = []\n",
    "docs = []\n",
    "\n",
    "for path in address_paths:\n",
    "    pres, year, doc = return_sotu_name_year_text(path)\n",
    "    presidents.append(pres)\n",
    "    years.append(year)\n",
    "    docs.append(doc)\n",
    "    \n",
    "data = list(zip(presidents, years, docs))\n",
    "\n",
    "pd.DataFrame(data, columns = [\"president\", \"year\", \"text\"]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(address_paths, columns = [\"file_path\"])\n",
    "df[[\"president\", \"year\", \"text\"]] = df.file_path.apply(lambda x: pd.Series(return_sotu_name_year_text(x)))\n",
    "df.drop(columns = [\"file_path\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=\"year\", inplace=True)\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(index=0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.president==\"Adams\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.year = df.year.apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.president = np.where(df.president.eq(\"Adams\") & df[\"year\"].gt(1800), \"Adams2\", df.president)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.president==\"Adams\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.president==\"Adams2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.president = np.where(df.president.eq(\"Bush\") & df[\"year\"].gt(2000), \"Bush2\", df.president)\n",
    "df.president = np.where(df.president.eq(\"Johnson\") & df[\"year\"].gt(1900), \"Johnson2\", df.president)\n",
    "df.president = np.where(df.president.eq(\"Roosevelt\") & df[\"year\"].gt(1930), \"Roosevelt2\", df.president)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.president.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.president.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.text = df.text.apply(str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?ord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'a = {ord(\"a\")}, z = {ord(\"z\")}, and space = {ord(\" \")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"This is a test string, and it has some punctuation--not a lot, but some--that we're going to remove.\"\n",
    "\n",
    "s2 = \"\"\n",
    "for char in s.lower():\n",
    "    if char == \" \" or ord(char) in range(97,123):\n",
    "        s2 += char\n",
    "    else:\n",
    "        s2 += \" \"\n",
    "        \n",
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_alphabetical(text: str) -> str:\n",
    "    \"\"\"Keep only lowercase a-z\"\"\"\n",
    "    return \"\".join([char if (ord(char) in range(97,123) or char == \" \") else \" \" for char in text])\n",
    "\n",
    "\n",
    "df.text = df.text.apply(lambda x: keep_alphabetical(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = \" \".join(df.text)\n",
    "\n",
    "word_frequencies = dict(Counter(all_text.split()))\n",
    "\n",
    "types_and_counts = sorted(list(word_frequencies.items()), reverse = True, key = lambda x: x[1])\n",
    "print(types_and_counts[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The corpus has {sum(word_frequencies.values()):,} words.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types_, token_counts = zip(*types_and_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 8))\n",
    "plt.bar(x = range(100), height = token_counts[:100])\n",
    "plt.title(\"Frequencies of Top 100 Terms in Corpus\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 8))\n",
    "plt.bar(x = types_[:20], height = token_counts[:20])\n",
    "plt.xticks(rotation = 90)\n",
    "plt.title(\"Frequencies of Top 20 Terms in Corpus\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_rank = np.log(range(1, len(token_counts)+1))\n",
    "log_frequencies = np.log(token_counts)\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.plot(log_rank, log_frequencies)\n",
    "plt.ylabel(\"ln(word frequency)\")\n",
    "plt.xlabel(\"ln(word rank)\")\n",
    "plt.title(\"Word Rank versus Frequency (log-log)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_of_types(document: str) -> str:\n",
    "    return \" \".join(list(set(document.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"this is a string that repeats some words, like string and words and some\"\n",
    "\n",
    "print(Counter(s.split())) # three types occur twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = set_of_types(s)\n",
    "\n",
    "print(Counter(s2.split())) # each type occurs only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"types\"] = df.text.apply(set_of_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_frequencies = dict(Counter(\" \".join(df.types).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"types\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = sorted(list(word_frequencies.keys()))\n",
    "\n",
    "x = [word_frequencies[word] for word in vocabulary]\n",
    "y = [document_frequencies[word] for word in vocabulary]\n",
    "\n",
    "print(\"Correlation between each word's frequency in the overall corpus and its document frequency:\")\n",
    "print(f\"Pearson's correlation coefficient: {pearsonr(x, y)[0]:.2f}\")\n",
    "print(f\"Spearman's rank-order correlation: {spearmanr(x, y)[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are interested in analyzing meaning from a corpus, in practice we will often remove words that appear only once or in only one document (which aren't the same thing!). We sometimes call these [hapaxes](https://en.wikipedia.org/wiki/Hapax_legomenon). We can't say that two documents have a word in common if only one document in the entire corpus has the word!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hapaxes = [word for word in vocabulary if document_frequencies[word] == 1]\n",
    "print(len(hapaxes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may often exclude words that appear in *every* document for similar reasons.\n",
    "\n",
    "Let's remove hapaxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_frequencies = {key:value for key, value in word_frequencies.items() if key not in hapaxes}\n",
    "document_frequencies = {key:value for key, value in document_frequencies.items() if key not in hapaxes}\n",
    "\n",
    "assert word_frequencies.keys() == document_frequencies.keys()\n",
    "\n",
    "types_and_counts = sorted(list(word_frequencies.items()), reverse = True, key = lambda x: x[1])\n",
    "vocabulary, _ = zip(*types_and_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"speech_title\"] = df.apply(lambda row: row[\"president\"].lower() + \"_\" + str(row[\"year\"]), axis = 1)\n",
    "df[\"wordcount\"] = df.text.apply(lambda x: len(x.split()))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 8))\n",
    "sns.scatterplot(x = \"year\", y = \"wordcount\", data = df)\n",
    "plt.title(\"Wordcount of State of the Union Address by Year\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Words\")\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.wordcount.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.wordcount.eq(df.wordcount.max())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document-Term Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = copy.copy(df)\n",
    "dtm.text = dtm.text.apply(str.split)\n",
    "dtm = dtm[[\"speech_title\", \"text\"]]\n",
    "dtm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_frequency(doc, vocab):\n",
    "    return [doc.count(term) for term in vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = [\"the\", \"cat\", \"in\", \"the\", \"hat\"]\n",
    "\n",
    "term_frequency(s, vocabulary[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in dtm.iterrows():\n",
    "    print(vocabulary[:10])\n",
    "    print(term_frequency(row.text, vocabulary[:10]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_voc = vocabulary[:3000]\n",
    "\n",
    "dtm[list(sub_voc)] = dtm.text.apply(lambda x: pd.Series(term_frequency(x, sub_voc))) # this takes a moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm.drop(columns=\"text\", inplace=True)\n",
    "dtm.set_index(\"speech_title\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Speeches in a 2D Space using Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_std = copy.copy(dtm)\n",
    "titles = dtm_std.index\n",
    "dtm_std = dtm_std.to_numpy()\n",
    "\n",
    "sd = np.std(dtm.to_numpy(), ddof = 1, axis = None)\n",
    "\n",
    "dtm_std = dtm_std - dtm_std.mean()\n",
    "dtm_std = dtm_std/sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_std.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "components = pca.fit_transform(dtm_std)\n",
    "\n",
    "pca_df = pd.DataFrame(data = components, columns = [\"orig_component1\", \"orig_component2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df[\"title\"] = titles\n",
    "pca_df[[\"president\", \"year\"]] = pca_df.title.apply(lambda x: pd.Series(x.split(\"_\")))\n",
    "pca_df.year = pca_df.year.apply(int)\n",
    "pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = pca_df[\"year\"] > 2000\n",
    "\n",
    "label_points = False\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns_plot = sns.scatterplot(x = \"orig_component1\", y = \"orig_component2\", data = pca_df[mask], hue=\"president\")\n",
    "plt.title(\"Distribution of Speeches According to First Two Components\")\n",
    "if label_points:\n",
    "    for idx, row in pca_df[mask].iterrows():\n",
    "        sns_plot.text(x = row[\"orig_component1\"], y = row[\"orig_component2\"], s = row[\"title\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_decade(year):\n",
    "    return str(year)[:-1] + \"0s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_decade(1990)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df[\"decade\"] = pca_df.year.apply(return_decade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 8))\n",
    "sns.scatterplot(x = \"orig_component1\", y = \"orig_component2\", data = pca_df, hue=\"decade\")\n",
    "plt.title(\"Distribution of State of the Union Addresses\\nAccording to First Two Components\")\n",
    "plt.legend(bbox_to_anchor=(1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using TF-IDF to Compare Documents\n",
    "\n",
    "Let's see if things improve if we use [tf-idf](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) weighting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_idf(N: int, df: int) -> float:\n",
    "    return np.log10(N/(1 + df))\n",
    "\n",
    "\n",
    "def tfidf_ind(doc: str, word: str) -> float:\n",
    "    tf = np.log(1 + doc.count(word))\n",
    "    idf = idf_dict[word]\n",
    "    return tf * idf\n",
    "\n",
    "\n",
    "def tfidf_vocab(doc: str, vocab: list) -> list:\n",
    "    return [tfidf_ind(doc, word) for word in vocab]\n",
    "    \n",
    "N = dtm.shape[0]\n",
    "    \n",
    "idf_dict = {word: return_idf(N, frequency) for word, frequency in document_frequencies.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([key for key, value in idf_dict.items() if value == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_mat = copy.copy(df)\n",
    "tfidf_mat.text = tfidf_mat.text.apply(str.split)\n",
    "tfidf_mat = tfidf_mat[[\"speech_title\", \"text\"]]\n",
    "tfidf_mat[list(sub_voc)] = tfidf_mat.text.apply(lambda x: pd.Series(tfidf_vocab(x, sub_voc))) # this takes a moment\n",
    "tfidf_mat.drop(columns=\"text\", inplace=True)\n",
    "tfidf_mat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_mat.set_index(\"speech_title\", inplace=True)\n",
    "titles = tfidf_mat.index\n",
    "tfidf_mat = tfidf_mat.to_numpy()\n",
    "\n",
    "sd = np.std(tfidf_mat, ddof = 1, axis = None)\n",
    "\n",
    "tfidf_mat = tfidf_mat - tfidf_mat.mean()\n",
    "tfidf_mat = tfidf_mat/sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_pca = PCA(n_components=2)\n",
    "components = tfidf_pca.fit_transform(tfidf_mat)\n",
    "\n",
    "tfidf_pca_df = pd.DataFrame(data = components, columns = [\"tfidf_component1\", \"tfidf_component2\"])\n",
    "tfidf_pca_df[\"title\"] = titles\n",
    "tfidf_pca_df[[\"president\", \"year\"]] = tfidf_pca_df.title.apply(lambda x: pd.Series(x.split(\"_\")))\n",
    "tfidf_pca_df.year = tfidf_pca_df.year.apply(int)\n",
    "tfidf_pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = tfidf_pca_df[\"year\"] > 2000\n",
    "tfidf_pca_df[mask]\n",
    "\n",
    "label_points = False\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns_plot = sns.scatterplot(x = \"tfidf_component1\", y = \"tfidf_component2\", data = tfidf_pca_df[mask], hue=\"president\")\n",
    "plt.title(\"Distribution of State of the Union Addresses\\nAccording to First Two Components\")\n",
    "if label_points:\n",
    "    for idx, row in tfidf_pca_df[mask].iterrows():\n",
    "        sns_plot.text(x = row[\"tfidf_component1\"], y = row[\"tfidf_component2\"], s = row[\"title\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_pca_df[\"decade\"] = tfidf_pca_df.year.apply(return_decade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 8))\n",
    "sns.scatterplot(x = \"tfidf_component1\", y = \"tfidf_component2\", data = tfidf_pca_df, hue=\"decade\")\n",
    "plt.title(\"Distribution of State of the Union Addresses\\nAccording to First Two Components\")\n",
    "plt.legend(bbox_to_anchor=(1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = tfidf_pca_df.decade.isin([\"1790s\", \"1890s\", \"1990s\"])\n",
    "\n",
    "label_points = False\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns_plot = sns.scatterplot(x = \"tfidf_component1\", y = \"tfidf_component2\", data = tfidf_pca_df[mask], hue=\"decade\")\n",
    "plt.title(\"Distribution of State of the Union Addresses\\nAccording to First Two Components\")\n",
    "plt.legend(bbox_to_anchor=(1.25, 1))\n",
    "if label_points:\n",
    "    for idx, row in tfidf_pca_df[mask].iterrows():\n",
    "        sns_plot.text(x = row[\"tfidf_component1\"], y = row[\"tfidf_component2\"], s = row[\"title\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse versus Dense Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of non-zero values in (truncated) document-term matrix: {np.count_nonzero(dtm)}\")\n",
    "print(f\"Number of entries in (truncated) document-term matrix: {dtm.size}\")\n",
    "print(f\"{np.count_nonzero(dtm)/dtm.size * 100:.0f}% of entries are zeros, and that's based on \"\n",
    "      \"the 3,000 most frequent words.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
